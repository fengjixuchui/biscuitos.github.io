---
layout: post
title:  "CACHE Mechanism[Updating]"
date:   2022-12-30 12:00:00 +0800
categories: [MMU]
excerpt: CACHE.
tags:
  - CACHE SYSTEM
  - Linux 6.0+
  - Hardware
  - BiscuitOS DOC 3.0+
---

![](/assets/PDB/BiscuitOS/kernel/IND00000L0.PNG)

#### 目录

> - [CACHE 基础概念](#A)
>
>   - [CACHE 结构之直接映射](#AX)
>
>   - [CACHE 结构之全相联映射](#AXD)
>
>   - [CACHE 结构之组相联映射](#ADF)
>
>   - [CACHE 别名问题](#xdfasd)
>
>   - [CACHE 歧义问题](#werfasdf)
>
>   - [CACHE Index/Tag VIVT](#AAAd)
>
>   - [CACHE Index/Tag PIPT](#AAAd)
>
>   - [CACHE Index/Tag VIPT](#AAAd)
>
>   - [CACHE Index/Tag PIVT](#AAAd)
>
>   - [CACHE 替换策略](#A70)
>
>   - [CACHE 一致性: MESI](#A80)
>
>   - [CACHE WB/WT/UC/WC](#dsfasdf)
>
>   - [CACHE 多级缓存架构]()
>
> - [Intel X86 架构 CACHE 机制](#B)
>
> - [CACHE 实践教程](#C)
>
> - [CACHE 使用教程](#D)
>
> - [CACHE 应用场景](#E)
>
> - [CACHE 进阶研究](#F)
>
>   - [Intel RDT](#X)

######  🙂🙂🙂🙂🙂🙂 捐赠一下吧 🙂🙂🙂🙂🙂🙂

![BiscuitOS](/assets/PDB/BiscuitOS/kernel/HAB000036.jpg)

-------------------------------------------

<span id="A"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000Q.jpg)

#### CACHE 基础概念

![](/assets/PDB/HK/TH002421.png)

CACHE 是由一组称为**缓存行(CACHE Line)**固定大小的数据块组成，其长度称为 **CACHE Line Size**, 在有的架构中 CACHE Line Size 为 64 个字节。每个 CACHE Line 完全是在一个突发读操作周期中进行填充或更新, 即使处理器只访问存储器上的一个字节，CACHE 控制器也会将 CACHE Line Size 的数据块加载到 CACHE 里. 同理将内存中 CACHE Line Size 大小的数据块称为 **Data Block**.

![](/assets/PDB/HK/TH002422.png)

CACHE Line 是 CACHE 最基础的组成单位，将 N 个 CACHE Line 组成的集合称为 **CACHE Set**, 那么称 CACHE 是 N 路组相联(N-Way Set-associative Cache), 所以从硬件结构来看 CACHE 被划分成 N 个垂直面，每个垂直面上有多个 CACHE Line，对所有的 CACHE 垂直面进行一次横切的 CACHE Line 合集就是 CACHE Set. CACHE Line 由两部分组成: Tag 和 Offset 部分，其中 Tag 字段由于匹配具体的 Data Block，Tag 字段中还包含了 valid 标志位，该位置位说明 CACHE Line 的内容有效，反之 CACHE Line 的内容无效。CACHE Line 的 Offset 部分存储 Data Block 的内容.

* **CACHE Hit(命中)**: 指的是 CPU 要访问的地址正好缓存在 CACHE Line 中
* **CACHE Miss(缺失)**: 指 CPU 要访问的地址没有缓存在 CACHE Line 中.
* **CACHE 颠簸**: 指的是 CPU 访问多个地址导致某个 CACHE Line 来回更新和填充.

##### 直接映射 

![](/assets/PDB/HK/TH002418.png)

**直接映射(Direct-mapped)** 指的是内存中的 data block 按顺序映射到指定的 CACHE Line, 且每个 data block 只能映射到一个 CACHE Line 里，那么内存 data block 与 CACHE Line 一一对应，那么可以使用一个线性公式表示两者之间的关系，这个线性公式是求模公式，模数即为 CACHE Line 的数量，内存地址求模之后就可以知道其映射的 CACHE Line，那么模相同的内存 data block 会映射到同一个 CACHE Line 里. 例如上图的案例中，内存 data block 的长度和 CACHE LINE 的长度都是 64Bytes，内存 data block 0x0000000 只能被加载到 CACHE Line0, 0x00000008 只能加载到 CACHE Line1，以此类推，由于 0x00000030 的模数与 0x00000000 相同，那么其也映射到 CACHE Line0 上。相比其他的 CACHE 设计方案，直接映射有自己的简单的优点，但缺点也很明显:

* **优点**: 硬件设计简单、成本低
* **缺点**: 灵活性差，内存 data block 只能映射到固定的 CACHE Line 上，很容易与同一 CACHE Line 的 data block 冲突，从而引起**Cache 颠簸**. CACHE 的容量比较大才能显示直接映射的优势.

![](/assets/PDB/HK/TH002415.png)

直接映射硬件设计简单, CACHE 内部在一个平面内将所有的 CACHE LINE 按顺序依次排列组成，每一行就是一个 CACHE Line，每个 CACHE Line 包含了两部分，TAG 和 OFFSET，其中 TAG 部分还包含了一个 valid 位，Valid 位置位时表示 CACHE Line 维护的数据有效, 反之该位清零时表示 CACHE Line 维护的数据无效. 硬件处理过程如上图:

* **A**: CPU 生成需要**访问地址**，地址被划分成 3 个部分: Tag、Index 和 Offset
* **B**: CACHE 从**访问地址**的 Index 部分在 CACHE 中找到对应的 CACHE Line
* **C**: 将 CACHE Line 的 Tag 部分与**访问地址**的 Tag 部分进行比较，当匹配上且 CACHE Line Tag 的 valid 位置位，那么**命中(Cache hit)**; 反之如果 valid 位清零或者 Tag 字段不匹配，那么**缺失(Cache miss)**.
* **D**: 当命中之后，CACHE 根据**访问地址**的 Offset 字段从 CACHE Line 中获得最终的值.

##### 全相联映射

![](/assets/PDB/HK/TH002419.png)

**全相联映射(Full-associative)** 指的是内存中的 data block 可以映射到任意 CACHE Line. 例如上图的案例中内存 0x00000000 可以映射到任一 CACHE Line 上，0x00000008 也可以映射到任一个 CACHE Line. 由于内存 data block 可以映射到任一 CACHE Line，因此 CACHE 需要花费更多的时间或者更多的资源去查找对应的 CACHE Line 中是否包含所需的数据.

* **优点**: 灵活性好，CACHE 只要要空闲的 CACHE Line 就可以加载内存 data block.
* **缺点**: 利用率不高，因为存在一个 m 位的标记，使 CACHE Line 中包含一些对存储无用的信息. 速度慢、硬件成本高，每次访问 CACHE 需要依次遍历，直到命中才能直到 data block 是否在 CACHE 中.

![](/assets/PDB/HK/TH002416.png)

全相联映射的硬件相对复杂，CACHE 内部在一个平面内将所有的 CACHE LINE 按顺序依次排列，每个 CACHE Line 都存在一个比较模块，用于比较 CACHE Line 的 Tag 部分，其中 TAG 部分还包含了一个 valid 位，Valid 位置位时表示 CACHE Line 维护的数据有效, 反之该位清零时表示 CACHE Line 维护的数据无效. 全>相联结果的 CACHE 有着最大的灵活性，因此缺失(Cache miss)率是最低的，但从硬件结构来看，由于有着大量的内容需要进行比较，它的延迟也是最大的，因此一般这种结构的 CACHE 都不会有很大的容量. 硬件处理过程如上图:

* **A**: CPU 生成需要**访问地址**，地址被划分成 2 个部分: Tag 和 Offset
* **B**: CACHE 从**访问地址**的 Tag 部分依次与 CACHE Line 的 Tag 部分进行比较
* **C**: 当匹配上且 CACHE Line Tag 的 valid 位置位，那么**命中(Cache hit)**; 反之如果 valid 位清零或者 Tag 字段不匹配，那么**缺失(Cache miss)**.
* **D**: 当命中之后，CACHE 根据**访问地址**的 Offset 字段从 CACHE Line 中获得最终的值.

##### 组相联映射

![](/assets/PDB/HK/TH002420.png)

**组相联映射(Set-associative)** 是直接映射和全映射的折中方案，将多个 CACHE Line 组成一个组称为 **CACHE Set**，同样将多个 Data block 组成一个组称为 **Data Set**，每个 Data Set 按直接映射的方式映射到指定的 CACHE Set. Data Set 内的任意 Data block 可以映射到 CACHE Set 中任意 CACHE Line. 对于组相联映射的 CACHE 来说，一个 Data block 可以被加载到 CACHE Set 的 N 个 CACHE Line，那么称这个 CACHE 是 N 路组相联的 CACHE(n-way set-associative Cache). 相比其他两种映射方式，组相联映射组内具有一定的灵活性，而且组内行数较少，比较的硬件电路比全相联方式简单，并且空间利用率比直接映射方式高.

![](/assets/PDB/HK/TH002422.png)

组相联映射的硬件是一个立体的结构，每个 CACHE Way 就是一个垂直平面，多个 CACHE Way 组成了一个立体的存储结构，那么一个 CACHE Set 就是在多个 CACHE Way 组成的立体结构上进行一次横切，那么同一个 Data Set 里面的 Data block 可以存储在横切之后 CACHE Set 里任意一个 CACHE Line 里. 硬件处理过程如上图:

* **A**: CPU 生成需要**访问地址**，地址被划分成 3 个部分: Tag、Index 和 Offset
* **B**: CACHE 从**访问地址**的 index 部分在 CACHE 中找到对应的 CACHE Set.
* **C**: 依次将 CACHE Set 里的 CACHE Line 的 Tag 部分与**访问地址**的 Tag 部分进行比较，如果匹配上且 Tag 的 valid 位置位，那么**命中(Cache hit)**; 反之如果 valid 位清零或者 Tag 字段没有匹配，那么**缺失(Cache miss)**.
* **D**: 当命中之后，CACHE 根据**访问地址**的 Offset 字段从 CACHE Line 中获得最终的值.

-----------------------------------

##### CACHE Tag and Index

![](/assets/PDB/HK/TH002432.png)

对于一段索引 CACHE 的内存地址(可以是虚拟机地址或者物理地址)，其分为以上三部分: Tag、Index 和 Offset. 三者组合可以在 CACHE 中定位唯一的 CACHE Line，其中 Index 字段用于定位 CACHE Set，Tag 用于在 CACHE Set 中定位到指定的 CACHE Line，Offset 用于在 CACHE Line 的数据域定位指定的数据.

![](/assets/PDB/HK/TH002433.png)

CACHE Line 内部结构如上图，其由 Tag、Flags 和数据域组成。Tag 部分用于在内存地址 Index 找到 CACHE Set 的情况下，与内存地址 Tag 相比较以此找到指定的 CACHE Line; Flags 字段包括 Valid 位，在数据 CACHE 中还包括 Dirty 位，Valid 位用于指明 CACHE Line 是否有效，Dirty 位则表明 CACHE Line 是否包含脏数据; Data 数据域包含了从 Data Block 取来的 CACHE Line Size 字节的数据.

![](/assets/PDB/HK/TH002434.png)

内存 Data Block 首次加载到 CACHE 时，先根据内存地址的 Index 字段在 CACHE 中找到对应的 CACHE Set，然后将 CACHE Set 中找到一个合适的 CACHE Line 将内存地址 Tag 字段存入 CACHE Line 的 Tag 字段，然后将内存 Data Block 的数据存储到 CACHE Line 的 Data 区域. 例如 Data Block 的地址为 0x00061000, 其 Index 为 1， 那么其被加载到 CACHE 时其会选择 CACHE Set 为 1，由于案例中 CACHE Set 只包含一个 CACHE Line，那么 Data Block 加载到 CACHE Line1 里，此时 CACHE 将 Data Block 的 Tag 字段 0x0006 存储到 CACHE Line1 的 Tag 字段，并将 Data Block 的数据加载到 CACHE Line1 的 Data 域. 以上便是一个最简单的 CACHE Load 内存的过程.

![](/assets/PDB/HK/TH002435.png)

在开启分页之后，CPU 直接使用的是虚拟地址，但索引 CACHE 的内存地址可以是物理地址，也可以是虚拟地址，存在这样的逻辑是因为 CACHE 的位置决定的。当 CACHE 位于 CPU 和 MMU 之间，那么称为**逻辑 CACHE**，可以使用虚拟地址的 Index 索引 CACHE Set，并称虚拟地址的 Index 为 **VI(Virtual Index)**; 当 CACHE 位于 MMU 和主存之间，那么称为 **物理 CACHE**, 可以使用物理地址的 Index 索引 CACHE Set，并称物理地址的 Index 为 **PI(Physical Index)**. 另外需要使用物理地址 Tag 确认 CACHE Line 的 Tag，那么物理地址 Tag 为 **PT(Physical Tag)**, 同理需要使用虚拟地址 Tag 确认 CACHE Line 的 Tag，那么虚拟地址 Tag 称为 **VT(Virtual Tag)**. 

------------------------------------

##### CACHE 歧义(Ambiguity)

![](/assets/PDB/HK/TH002436.png)

当 CACHE 控制器使用虚拟地址索引 CACHE Line，即使用 VIVP(Virtual Index Virtual Tag)，当两个进程相同的虚拟地址映射到不同的物理地址，例如上图中进程 0 的虚拟地址 0x1000000108 映射了物理地址 0x200020, 而进程 1 同样的虚拟地址 0x1000000108 映射了物理地址 0x300020. 由于 CACHE 控制器使用了虚拟地址 Index 所有 CACHE Set，那么两个虚拟地址的 Index 都是 0x01, 并且使用虚拟地址的 Tag 确认 CACHE Line 的 Tag，此时两个虚拟地址都有相同的 Tag，因此两个进程的虚拟地址在 CACHE 中找到了同一个 CACHE Line，换个角度就是**同一个 CACHE Line 映射不同的物理地址**, 称这种现象为 **CACHE 歧义(Ambiguity)**. 内核通过如下方法避免歧义:

* 进程切换时 flush cache，并使主存 Data Block 有效。针对 WriteBack 高速缓存，首先应使主存数据有效，保证已经修改数据 CACHE Line 已经写会主存，避免修改的数据丢失.
* 进程切换时 flush cache，并使 CACHE Line 无效，保证切换之后的进程不会错误命中切换之前进程的 CACHE Line.

##### CACHE 别名(Alias)

![](/assets/PDB/HK/TH002437.png)

当 CACHE 控制器使用虚拟地址索引 CACHE Line，即使用 VIVP(Virtual Index Virtual Tag). 当两个进程不同的虚拟地址映射到同一个物理地址上，例如上图进程 0 的虚拟地址 0x1000000108 和进程 1 的虚拟地址 0x8000000206 都映射到了物理地址 0x3000200，由于 CACHE 控制器使用 VIVP，那么此时就会出现两个虚拟地址会索引到不同 CACHE Set 的 CACHE Line 上，换个角度就是**一个物理地址被缓存到不同的 CACHE Line 里**，称这种现象为 **CACHE 别名(Alias)**. 别名问题会导致 CACHE 一致性问题(后面会讨论).

------------------------------------------

##### VIVT

![](/assets/PDB/HK/TH002438.png)

**VIVT(Virtual Index Virtual Tag)** 指的是**虚拟 CACHE 控制器**通过虚拟地址提供的 Tag 和 Index 索引 CACHE Line. VIVT 不需要经过 MMU 翻译，具有很小的延时，但会引起**别名**和**歧义**问题.

![](/assets/PDB/HK/TH002439.png)

**VIVT CACHE Hit**: 当 CACHE 控制器使用 VIVT 索引 CACHE Line:

* **(A)** CPU 产生的虚拟地址可以直接传递给 CACHE 控制器进行索引
* **(B)** CACHE 控制器从虚拟地址中提取 Index 字段，Index 可以选择指定的 CACHE Set，此时选中 CACHE Set1，其组内包含了两个 CACHE Line
* **(C)** CACHE 控制器从虚拟地址中提取 Tag 字段，与 CACHE Set1 的所有 CACHE Line 的 Tag 字段进行比较，一旦 Tag 匹配，并且 Valid 字段有效，那么找到指定的 CACHE Line.
* **(D)** CACHE 控制器从 CACHE Line 中区域 Data 区域，并从虚拟地址提取 Offset 字段，最终在 CACHE Line 的 Data 区域中读取指定的数据.

![](/assets/PDB/HK/TH002440.png)

**VIVT CACHE Miss**: 当 CACHE 控制器使用 VIVT 索引 CACHE Line:

* **(A)** CPU 产生的虚拟地址可以直接传递给 CACHE 控制器进行索引
* **(B)** CACHE 控制器从虚拟地址中提取 Index 字段，Index 可以选择指定的 CACHE Set，此时选中的 CACHE Set1，其组内包含了两个 CACHE Line.
* **(C1)** CACHE 控制器从虚拟地址中提取 Tag 字段，与 CACHE Set1 的第一个 CACHE Line 的 Tag 字段进行比较，发现不匹配
* **(C2)** CACHE 控制器继续与 CACHE Set1 剩下的 CACHE Line Tag 字段进行比较，发现还是不匹配，那么 CACHE 控制器认为发送 CACHE Miss
* **(C3)** CACHE Miss 之后 CACHE 控制器将虚拟地址传递给 TLB 或者 MMU 查询虚拟地址对应的物理内存
* **(C4)** 系统从 TLB 或者 MMU 中找到了虚拟地址对应的物理内存(可能也找不到)
* **(D)** CACHE 控制器根据替换算法将 CACHE Set1 中指定的 CACHE Line 刷出，然后将找到的物理内存 Data Block 加载到该 CACHE Line，并更新 Tag 和 Valid 字段
* **(E)** CACHE 控制器继续将 CACHE Line 的 Data 域取出，然后配合虚拟地址的 Offset 域找到最终的数据.

**VIVT 优缺点**: 通过上面对 VIVT Hit 和 Miss 场景的分析，VIVI 模式下 CPU 不需要将虚拟地址转换成物理地址就可以在 CACHE 中找到 CACHE Line，在一定程度上提升了 CACHE 的速度，因为访问虚拟地址转换成物理地址可能需要几十到几百个周期，只有在 CACHE Miss 的时候才会发送虚拟地址到物理地址的转换，硬件设计上更加简单. 但 VIVT 模式容易引入歧义和别名问题, 具体如下:

![](/assets/PDB/HK/TH002441.png)

在不同的进程地址空间里，虚拟地址虽然相同，但映射到不同的物理内存上，如果 CACHE 控制器使用虚拟地址的 Index 和 Tag 查找 CACHE Line，那么会出现**同一个 CACHE Line 会映射不同的物理地址**，这就是 **VIVT 的歧义问题**. 为了保证系统的正确工作，操作系统需要负责避免歧义出现，可以通过按需清除 CACHE Line，或者为每一个进程的地址空间添加标记(PCID/ASID)，当进程切换时刷掉指定的 CACHE Line, 不过这样做会导致进程调度回来时出现大量的 CACHE Miss，影响程序的性能.

![](/assets/PDB/HK/TH002442.png)

同样是不同进程不同的虚拟地址同时映射到同一个物理地址上，如果 CACHE 控制器使用虚拟地址的 Index 和 Tag 查找 CACHE Line，那么不同的虚拟地址可以找到不同的 CACHE Line，但找到的 CACHE Line 却缓存了同一个物理地址的 Data Block，也就**同一个物理地址会被映射到不同的 CACHE Line**，这就是 **VIVT 的别名问题**. 该问题会引起 CACHE 的一致性问题，例如更新了存在别名 CACHE Line 的数据，那么同别名的 CACHE Line 的数据没有被更新，导致 CACHE 数据一致性问题. 同歧义问题一样，可以通过 Flush CACHE 的方式避免别名问题，也可以针对共享的数据映射相同物理地址时采用 NOCACHE 的方式，但这样会损失 CACHE 带来的性能提升. 

-----------------------------------

##### PIPT

![](/assets/PDB/HK/TH002443.png)

**PIPT(Physical Index Physical Tag)** 指的是**物理 CACHE 控制器**通过物理地址提供的 Tag 和 Index 索引 CACHE Line. PIPT 需要将 CPU 产生的虚拟地址经过 TLB/MMU 翻译，获得物理地址之后才能在 CACHE 中查找 CACHE Line，因此 CACHE 的速度受限于 TLB/MMU 转换的效率. 由于物理地址的唯一性，那么 Physical Index 和 Physical Tag 也具有唯一性，那么不会引入 **CACHE 别名问题**和 **CACHE 歧义问题**.

![](/assets/PDB/HK/TH002444.png)

**PIPT CACHE Hit**: 当 CACHE 控制器使用 PIPT 索引 CACHE Line 发生 CACHE Hit:

* **(A)** CPU 产生的虚拟地址首先传递给 TLB/MMU 进行地址转换
* **(B)** TLB/MMU 将虚拟地址转换成物理地址, 并传递给 CACHE 控制器
* **(C)** CACHE 控制器从物理地址中提取 Index 字段，然后找到对应的 CACHE Set1，组内包含了两个 CACHE Line
* **(D1)** CACHE 控制器从物理地址中提取 Tag 字段，然后与 CACHE Set1 组内第一个 CACHE Line 的 Tag 字段进行比较，此时两个 Tag 字段并不匹配.
* **(D2)** CACHE 控制器继续与 CACHE Set1 组内最后一个 CACHE Line 的 Tag 字段进行比较，此时两个 Tag 匹配，并检查到 Valid 字段有效，那么 CACHE Hit
* **(E)** CACHE 控制器从匹配 CACHE Line 中提取其 Data 域，并从物理地址中提取 Offset 字段，最后从 Data 域中获得所需的数据.

![](/assets/PDB/HK/TH002445.png)

**PIPT CACHE Miss**: 当 CACHE 控制器使用 PIPT 索引 CACHE Line 发生 CACHE Miss:

* **(A)** CPU 产生的虚拟地址首先传递给 TLB/MMU 进行地址转换
* **(B)** TLB/MMU 将虚拟地址转换成物理地址，并传递给 CACHE 控制器
* **(C)** CACHE 控制器从物理地址中提取 Index 字段，然后找到对应的 CACHE Set1，组内包含了两个 CACHE Line
* **(D1)** CACHE 控制器从物理地址中提取 Tag 字段，然后与 CACHE Set1 组内第一个 CACHE Line 的 Tag 字段进行比较，此时两个 Tag 字段并不匹配.
* **(D2)** CACHE 控制器继续与 CACHE Set1 组内最后一个 CACHE Line 的 Tag 字段进行比较，此时两个 Tag 还是不匹配(或者就算 Tag 匹配但 Valid 域无效)，那么 CACHE Miss
* **(E)** CACHE 根据物理地址在主内存中找打对应的 Data Block
* **(F)** CACHE 根据一定的替换算法在 CACHE Set1 中指定的 CACHE Line 刷出，然后将主内存 Data Block 加载到 CACHE Line，并更新 Tag 和 Valid 字段
* **(G)** CACHE 控制器从新更新的 CACHE Line 中提取其 Data 域，并从物理地址中提取 Offset 字段，最后从 Data 域中获得所需的数据.

![](/assets/PDB/HK/TH002446.png)

在不同的进程地址空间里，虚拟地址相同，但映射到不同的物理内存上，如果 CACHE 控制器使用物理地址的 Index 和 Tag 查找 CACHE Line，那么不会出现**歧义问题**. 由于物理地址的唯一性，就算虚拟地址相同，但物理地址是不同的，因此可以**保证 Index 和 Tag 索引到的 CACHE Line 只映射一个的物理地址**, 从而避免了 CACHE 歧义问题.

![](/assets/PDB/HK/TH002447.png)

同样是不同进程不同的进程的空间虚拟地址映射到同一个物理地址，如果 CACHE 控制器使用物理地址的 Index 和 Tag 查找 CACHE Line，那么不会出现**别名问题**. 由于物理地址的唯一性，就算不同的虚拟地址映射到同一个物理地址，因此可以**保证物理地址只被加载到一个 CACHE Line 中**，从而避免了 CACHE 别名问题.

**PIPT 优缺点**: PIPT 带来的好处是很明显的，软件层面基本不需要任何维护就可以避免歧义和别名问题，但硬件设计上比 VIVT 复杂很多，因此硬件成本更高。最后对一个架构来说，CPU、TLB/MMU 和 CACHE 是三个不同的硬件模块，如果采用 PIPT 的话，CPU 发出虚拟地址经过 TLB/MMU 地址转译获得物理地址之后，CACHE 才能进行查询，这个串行操作直接损害性能, 因此没有 VIVT 高效.

-----------------------------------

##### VIPT

![](/assets/PDB/HK/TH002448.png)

**VIPT(Virtual Index Physical Tag)** 指的是**物理 CACHE 控制器**通过虚拟地址提供的 Index 和物理地址提供的 Tag 索引 CACHE Line. CPU 产生虚拟地址之后，可以同时将虚拟地址传递给 CACHE 控制器和 TLB/MMU 并发处理，这样索引 CACHE Set 和地址转译在时间上并发。歧义问题和别名问题在 VIPT 中是不存在的。

![](/assets/PDB/HK/TH002449.png)

**VIPT CACHE Hit**: 当 CACHE 控制器使用 VIPT 索引 CACHE Line 发生 CACHE Hit:

* **(A)** CPU 产生的虚拟地址同时传递给 CACHE 控制器和 TLB/MMU 组件
* **(B1)** 虚拟地址传送给 TLB/MMU 进行地址转译，以此获得物理地址
* **(B2)** 虚拟地址传送给 CACHE 控制器之后，提取虚拟地址的 Index 字段在 CACHE 中找到 CACHE Set1，组内包含两个 CACHE Line
* **(C)** TLB/MMU 地址转译完毕获得物理地址
* **(D1)** CACHE 控制器从物理地址中提取 Tag 字段与 CACHE Set1 第一个 CACHE Line 的 Tag 字段进行比对，结果不匹配
* **(D2)** CACHE 继续将物理地址提取的 Tag 字段与 CACHE Set1 的最后一个 CACHE Line 的 Tag 字段进行比对，匹配成功，并且此时 CACHE Line 的 Valid 字段有效，CACHE Hit.
* **(E)** CACHE 将匹配到的 CACHE Line Data 域取出，然后从物理地址或虚拟地址中获得 Offset 字段，最终从 Data 域中获得所需的数据.

![](/assets/PDB/HK/TH002450.png)

**VIPT CACHE Miss**: 当 CACHE 控制器使用 VIPT 索引 CACHE Line 发生 CACHE Miss:

* **(A)** CPU 产生的虚拟地址同时传递给 CACHE 控制器和 TLB/MMU 组件
* **(B1)** 虚拟地址传送给 TLB/MMU 进行地址转译，以此获得物理地址
* **(B2)** 虚拟地址传送给 CACHE 控制器之后，提取虚拟地址的 Index 字段在 CACHE 中找到 CACHE Set1，组内包含两个 CACHE Line
* **(C)** TLB/MMU 地址转译完毕获得物理地址
* **(D1)** CACHE 控制器从物理地址中提取 Tag 字段与 CACHE Set1 第一个 CACHE Line 的 Tag 字段进行比对，结果不匹配
* **(D2)** CACHE 继续将物理地址提取的 Tag 字段与 CACHE Set1 的最后一个 CACHE Line 的 Tag 字段进行比对，结果不匹配(或者匹配当 Valid 无效)，那么 CACHE Miss.
* **(E)** CACHE 控制器根据物理地址在主存中找到对应的 Data Block
* **(F)** CACHE 控制器在 CACHE Set1 根据替换算法将指定的 CACHE Line 刷出，然后将 Data Block 加载到 CACHE Line，并更新 Tag 和 valid 字段
* **(G)** CACHE 将新更新的 CACHE Line Data 域取出，然后从物理地址或虚拟地址中获得 Offset 字段，最终从 Data 域中获得所需的数据.

![](/assets/PDB/HK/TH002451.png)

在 VIPT 场景下，当两个进程的地址空间相同的虚拟地址映射到不同的物理地址，那么两个虚拟地址的 Index 是相同的，因此 CACHE 会定位到相同的 CACHE Set，但由于 CACHE Set 内包含多个 CACHE Line，由于物理地址的唯一性，不同的物理地址的 Tag 是不相同的，因此该场景下会对应两个不同的 CACHE Line，因此 VIPT 不存在**歧义问题**.

![](/assets/PDB/HK/TH002453.png)

在 VIPT 场景下，当不同进程的地址空间不相同的虚拟地址映射到同一个物理地址，那么两个虚拟地址的 Index 不相同，因此物理内存 Data block 可以加载到任意多个 CACHE Set。该场景下假设 CACHE 控制器通过虚拟地址 Index 找到 CACHE Set 之后，根据物理 Tag 发现该 CACHE Set 的所有 CACHE Line Tag 都不匹配，但物理内存的 Data block 已经加载到另外的 CACHE Set，CACHE 控制器现在无法获得其他 CACHE Set 的信息，因此引起了**别名问题**.

![](/assets/PDB/HK/TH002454.png)

**4KiB 别名问题**: 对于 VIPT 的别名问题，在 Linux 上是有解法的，例如在 8-Way 32KiB 组相联映射 CACHE 中 CACHE Line Size 为 64Bytes，一共包含 64 个 CACHE Set，因此需要虚拟地址提供 6bits 作为 Index。当映射 4KiB 物理页时，其包含 64 个 Data Block，将 8 个 Data Block 作为一组，其中物理地址 \[0:5\] 作为 Offset 字段，物理地址 \[7:11\] 寻址所有的 CACHE Set，实际只需要 3bit 就可以寻址所有 Data Block 组。由于映射 4KiB 页的低 12 位虚拟地址的内容和物理地址一致，那么虚拟地址 Index 6bit 与物理地址 \[7:11\] 字段内容是一致的，此时虚拟地址 Index 等效于物理地址 Index, 因此可以解决 VIPT 别名问题.

![](/assets/PDB/HK/TH002455.png)

**2MiB 别名问题**: 在 8-Way 32KiB 组相联映射 CACHE 中 CACHE Line Size 为 64Bytes，一共包含 64 个 CACHE Set，因此需要虚拟地址提供 6bits 作为 Index。当映射 2MiB 物理页时，其包含 32768 个 Data Block，将 8 个 Data Block 作为一组，一共 4096 Data block 组。其中物理地址 \[0:5\] 作为 Offset 字段，物理地址 \[7: 11\] 可以寻址所有的 CACHE Set, 实际需要 12bit 才能寻址所有的 Data Block 组，由于映射 2MiB 页的低 20 位虚拟地址的内容和物理地址一致，因此只要虚拟地址 6Bit 位于低 20 bit，那么虚拟地址 Index 就和物理 Index 一致，可以做到 2MiB 页内的物理地址只会加载到唯一的 CACHE Set 中，也可以解决 VIPT 的别名问题.

![](/assets/PDB/HK/TH002456.png)

**直接映射别名问题**: 在 8KiB 采用直接映射的 CACHE 中，CACHE Line Size 为 256 字节，其一共包含 32 个 CACHE Line，因此虚拟地址需要提供 5bit 寻址 CACHE Line，9 bit 用于 Offset 字段。在映射 4KiB 物理页的场景中，由于虚拟地址 \[0:8\] 区域用于 Offset 字段，虚拟地址 \[9:14\] 区域用于 Index 字段，由于 4KiB 映射物理页只有低 12 位虚拟地址和物理地址内容相同，因此此时虚拟地址 Index 不等效于物理地址 Index，因此会出现**别名问题**; 但同样的环境映射 2MiB 的物理页，由于低 20 位虚拟地址和物理地址内容一致，因此此时虚拟地址 Index 等效物理地址 Index, 此时不存在别名问题. 

**VIPT 别名问题总结**: 通过上面的案例分析，VIPT 要避免别名问题与 CACHE 的映射方式有关: 当使用组相联映射时，CACHE Set 的数量会影响别名问题，具体来说 CACHE Set 越大越容易引发别名问题; 当使用直接映射时，CACHE Line Size 会影响别名问题，当 CACHE Line Size 越大，Index 字段就会超过 4KiB/2MiB 低一致位，那么更容易引发一致性问题. 目前主流解决 VIPT 问题就是是 CACHE 采用组相联映射方式，CACHE 规模为 32KiB 8-Way(CACHE Line Size: 64B). 对于目前处理器 L1 CACHE 都是 VIPT，可以和 TLB/MMU 并发 CACHE 查询过程，但 VIPT 不是所有级 CACHE 的最佳选择，CACHE 越大需要的 Index 字段越大，那么越容易引发别名问题，因此 L2/L3 采用物理地址 Index 是最佳选择.

--------------------------------------------

##### PIVT

![](/assets/PDB/HK/TH002457.png)

**PIVT(Physical Index Virtual Tag)** 指的是**物理 CACHE 控制器**通过物理地址提供的 Index 和虚拟地址提供的 Tag 索引 CACHE Line. CPU 产生虚拟地址之后，PIVT 并不能像 VIPT 那样并发的在 CACHE 和 TLB/MMU 中工作，因为 CACHE 在查找 CACHE Line 时需要先定位 CACHE Set，再结合 Tag 字段才能定位 CACHE Line，但 PIVT 首先需要将虚拟地址传递给 TLB/MMU 进行地址转译，获得物理地址 Index 字段之后传递给 CACHE 才能定位 CACHE Set，最后根据虚拟地址的 Tag 定位 CACHE Line. PIVT 既包含了别名和歧义问题，而且性能也比 VIVT 或者 VIPT 方式慢很多.

![](/assets/PDB/HK/TH002458.png)

**PIVT CACHE Hit**: 当 CACHE 控制器使用 PIVT 索引 CACHE Line 发生 CACHE Hit:

* **(A)** CPU 产生虚拟地址
* **(B)** CPU 将虚拟地址传递给 TLB/MMU 进行地址转译
* **(C)** TLB/MMU 地址转译完毕，获得物理地址
* **(D)** 将物理地址的 Index 传递给 CACHE 控制器，匹配到 CACHE Set1，组内包含了两个 CACHE Line
* **(E1)** CACHE 控制器从虚拟地址提取 Tag 字段与 CACHE Set1 第一个 CACHE Line 的 Tag 字段进行比对，结果发现不匹配
* **(E2)** CACHE 控制器继续与 CACHE Set1 的最后一个 CACHE Line 的 Tag 字段进行比对，发现匹配且 CACHE Line 的 Valid 位有效，那么 CACHE Hit.
* **(F)** CACHE 将匹配到的 CACHE Line Data 域取出，然后从物理地址或虚拟地址中获得 Offset 字段，最终从 Data 域中获得所需的数
据.

![](/assets/PDB/HK/TH002459.png)

**PIVT CACHE Miss**: 当 CACHE 控制器使用 PIVT 索引 CACHE Line 发生 CACHE Miss:

* **(A)** CPU 产生虚拟地址
* **(B)** CPU 将虚拟地址传递给 TLB/MMU 进行地址转译
* **(C)** TLB/MMU 地址转译完毕，获得物理地址
* **(D)** 将物理地址的 Index 传递给 CACHE 控制器，匹配到 CACHE Set1，组内包含了两个 CACHE Line
* **(E1)** CACHE 控制器从虚拟地址提取 Tag 字段与 CACHE Set1 第一个 CACHE Line 的 Tag 字段进行比对，结果发现不匹配
* **(E2)** CACHE 控制器继续与 CACHE Set1 的最后一个 CACHE Line 的 Tag 字段进行比对，结果发现不匹配或者就算匹配，当 CACHE Line 的 Valid 标志位无效，因此 CACHE Miss.
* **(F)** CACHE 控制器利用物理地址在主存中找到对应的 Data Block
* **(G)** CACHE 控制器根据一定的替换算法将 CACHE Set1 中的某个 CACHE Line 刷出去，然后将找到的 Data Block 加载到该 CACHE Line 里
* **(H)** CACHE 将匹配到的 CACHE Line Data 域取出，然后从物理地址或虚拟地址中获得 Offset 字段，最终从 Data 域中获得所需的数
据.

![](/assets/PDB/HK/TH002460.png)

在不同的进程地址空间，虚拟地址虽然相同，但映射到不同的物理内存，如果 CACHE 控制器使用物理地址 Index 和虚拟地址 Tag 查找 CACHE Line，那么会出现**同一个 CACHE Line 映射不同的物理地址**，这就是 PIVT 的歧义问题. 为了保证系统的正确工作，操作系统需要负责避免歧义出现，可以通过按需清除 CACHE Line，或者为每一个进程的地址空间添加标记(PCID/ASID)，当进程切换时刷掉指定的 CACHE Line, 不过这样做会导致进程调度回来时出现大量的 CACHE Miss，影响程序的性能.

![](/assets/PDB/HK/TH002461.png)

同样是不同进程的地址空间不同的虚拟地址映射到同一个物理地址上，如果 CACHE 控制器使用物理地址的 Index 和虚拟地址 Tag 查找 CACHE Line，那么由于同一个物理地址，因此会定位到同一个 CACHE Set，但由于 Tag 不同，那么不同的虚拟地址 Tag 会定位到不同的 CACHE Line，此时**出现了同一个物理地址被映射到不同 CACHE Line**, 这就是 **PIVT 的别名问题**. 该问题会引起 CACHE 的一致性问题，例如更新了存在别名 CACHE Line 的数据，那么同别名的 CACHE Line 的数据没有被更新，导致 CACHE 数据一致性问题. 同歧义问题一样，可以通过 Flush CACHE 的方式避免别名问题，也可以针对共享的数据映射相同物理地址时采用 NOCACHE 的方式，但这样会损失 CACHE 带来的性能提升.

**PIVT 优缺点**: 通过上面对 PIVT 进行分析，发现 PIVT 具有 VIVT 的别名和歧义缺点，另外还没有 VIPT 并行特点，因此 PIVT 并没有任何优势可言.

###### VIVT/VIPT/PIPT/PIVT 总结

CACHE 对 CPU 的性能至关重要，目前主流处理器 L1 CACHE 采用 VIPT，CACHE 控制器通过虚拟地址 Index 取出一组 CACHE Line，同时并行进行 TLB/MMU 地址转译获得物理地址 Tag，最后从 CACHE Line 组中找到目标 CACHE Line，另外 Index 字段所需的位数在页表页偏移之内，那么虚拟地址 Index 是等效于物理地址 Index，那么这个时候不存在歧义和别名问题。但 VIPT 并不是所有级 CACHE 的首选，随着 CACHE 体积变大，Index 字段的长度会不断变大，当超过虚拟内存映射物理内存页内偏移区域之后，虚拟地址 Index 不再等效于物理地址 Index，便会增加歧义和别名问题的概率，因此 L2/L3 CACHE 选择 PIPT 的索引方式，这样可以避免歧义和别名问题. VIVT 软件维护成本太高，并会引入歧义和别名问题，需要在进程切换时 Flush 指定的 CACHE Line，软件管理难度大。现在主流使用 VIPT 和 PIPT。在多路组相联的 CACHE 中，CACHE Way 的大小等于 4KiB，一般硬件采用 VIPT 方式可以有效避免歧义和别名问题，等效于 PIPT; 当 CACHE Way 的大小大于 4KiB，一般采用 PIPT 方式，可以减轻操作系统的压力.

-----------------------------------

##### CACHE 回写/通写

![](/assets/PDB/HK/TH002423.png)

CACHE 写数据分为两种情况: 1. **将被改写的数据在 CACHE 中**. 2. **被改写的数据不在 CACHE 中**. 针对情况 1，CACHE 有两种策略来写数据:

* **回写(Write Back)**: 只改写 CACHE 中的 CACHE Line，不更新主存 Data Block. 优点是速度快，因为不用访问速度较慢的主存，缺点是只改写了 CACHE Line，CACHE Line 和主存 Data Block 数据不再一致，如果有别的核来访问主存中的 Data Block，那么它将读到错误的数据。另外在 CACHE Line 被替换出去的时候，数据应该被写入主存 Data Block，这就需要系统判断哪些 CACHE Line 被更新过，反应在电路上就需要增加一个 Dirty 位，当一个被标记为 Dirty 的 CACHE Line 被替换出去，其内容要被更新到主存.
* **通写(Write Through)**: 改写 CACHE 中的 CACHE Line 和主存 Data Block. 优点是时刻保持存储器数据一致，缺点是每次 store 指令都需要更新主存中的 Data Block，这个延时代价特别高.

针对第二种情况, 被改写的数据不在 CACHE 中，也有两种策略: 1. **直接把数据写入主存 Data Block，称为写不分配**. 2. **先把 Data block 放到 CACHE Line，然后回写或通写，称为写不分配**. 一般情况下，**回写**和**写分配**组合，**通写**和**写不分配**组合.

![](/assets/PDB/HK/TH002424.png)

上图是**通写**和**写不分配**的处理逻辑，当 CPU 执行了 Load/Store 指令需要读写数据，可能出现一下几种情况:

* **Load CACHE Hit**: 此时 Load 需要读取的数据在 CACHE 中，那么直接从 CACHE Line 中读取 Load 所需的数据.
* **Load CACHE Miss**: 此时 Load 需要读取的数据不在 CACHE 中，那么首先从 CACHE 中找到一块 CACHE Line，然后从主存中将 Data Block 加载到 CACHE Line 中，最后从 CACHE Line 中读取 Load 所需的数据.
* **Store CACHE Hit**: 此时 Store 需要写入的数据在 CACHE 中，那么先将 Store 指令写入的数据写入到 CACHE Line 中，然后写入到主存的 Data Block.
* **Store CACHE Miss**: 此时 Store 需要写入的数据不在 CACHE 中，那么直接将 Store 指令写入的数据写入到主存的 Data Block 里.

![](/assets/PDB/HK/TH002425.png)

上图是**回写**和**写分配**的处理逻辑，当 CPU 执行 Load 指令需要读数据，可能出现以下几种情况:

* **Load CACHE Hit**: 此时 Load 需要读取的数据在 CACHE 中，那么直接将对应 CACHE Line 的数据返回给 Load 指令.
* **Load CACHE Miss 且 CACHE Line No Dirty**: 此时 Load 需要读取的数据不在 CACHE 中，CACHE 找了一块 No-Dirty 的 CACHE Line 加载 主存中的 Data Block，并将 CACHE Line 标记为 No-Dirty, 最后将 CACHE Line 的数据返回给 Load 指令.
* **Load CACHE Miss 且 CACHE Line Dirty**: 此时 Load 需要读取的数据不在 CACHE 中，CACHE 找到一块 Dirty 的 CACHE Line，先将 CACHE Line 更新到主存，然后将主存中的 Data Block 加载到 CACHE Line 中，并标记 CACHE Line 为 No-Dirty，最后将 CACHE Line 的数据返回给 Load 指令.

当 CPU 执行 Store 指令需要写数据时，可能会出现一下几种情况:

* **Store CACHE Hit**: 此时 Store 需要写入的 Data Block 已经在 CACHE 中，那么直接将 Store 指令写如的数据更新到 CACHE Line 中，然后将 CACHE Line 标记为 Dirty.
* **Store CACHE Miss 且 CACHE Line No Dirty**: 此时 Store 需要写入的 Data Block 不在 CACHE 中，那么 CACHE 首先找到了一块 No-Dirty 的 CACHE Line，然后将主存中的 Data Block 加载到 CACHE Line，接着将 Store 指令需要的数据写入到 CACHE Line，最后将 CACHE Line 标记为 Dirty.
* **Store CACHE Miss 且 CACHE Line Dirty**: 此时 Store 需要写入的 Data Block 不在 CACHE 中，那么 CACHE 首先找到了一块 Dirty 的 CACHE Line，然后将 CACHE Line 的内容刷新到主存中，接着将主存中的 Data Block 加载到 CACHE Line 中，并将 Store 指令的数据写入到 CACHE Line 中，最后将 CACHE Line 标记为 Dirty.

--------------------------------

##### <span id="A70">CACHE 替换策略</span>

![](/assets/PDB/HK/TH002426.png)

无论 CPU 执行 Store/Load 读或写数据时，一旦 CACHE 发生 CACHE Miss，那么需要替换某个 CACHE Line，然后将所需的 Data Block 加载到 CACHE Line。Load 读数据 CACHE Miss 时需要从主存中将 Data Block 加载到 CACHE 中，这个 Data Block 需要替换某个 CACHE Line，这时需要替换算法决定顶替谁; Store 写数据 CACHE Miss 时如果是**写分配**，那么需要将主存中的 Data Block 加载到 CACHE 中，因此 CACHE 也需要决定 Data Block 替换哪个 CACHE Line. CACHE 支持多种替换算法，包括 **FIFO(先进先出)**、**LRU(最近最少使用)** 和**随机替换**策略等.

###### LRU(最近最少使用) 策略

![](/assets/PDB/HK/TH002427.png)

**LRU 策略**的基本思想就是选择最近一段实践使用次数最少的 CACHE Line 进行替换. CACHE 控制器需要对一个 CACHE Set 中的每个 CACHE Line 的使用情况进行跟踪，可以通过每一个 CACHE Line 都设置**年龄位**, 但起始状态所有 CACHE Line 都没有使用过，因此只需记录已经被使用的 CACHE Line 的年龄，例如 2-Way 的 CACHE，其每个 CACHE Set 有两个 CACHE Line，但只需一个年龄位，其通过如下逻辑进行判断:

* 当两个 CACHE Line 一直没有使用，那么年龄位一直为 0，那么替换时直接选择 CACHE Line0 替换出去
* 当 CACHE Line1 被使用，年龄位依旧保持 0，那么替换时选择 CACHE Line0 替换出去
* 当 CACHE Line0 被使用，年龄位设置为 1，那么替换的时候选择 CACHE Line1 替换出去

通过案例可以知道，在 2-Way 的 CACHE Set 一个年龄位置位或者清零已经表示有一个 CACHE Line 年龄已经变大. 如果 CACHE Set 里包含的 CACHE Line 越来越多，那么N-Way CACHE Set 需要 **Log2(N)**

![](/assets/PDB/HK/TH002428.png)

在 8-Way CACHE 中，CACHE Set 采用了 3 个年龄位，每个年龄位被分成不同的年龄级层，Age-level-0 用于将 CACHE Set 中的 CACHE Line 分作两半，当 Age-level-0 置位，那么表示 CACHE Line0 到 CACHE Line3 没有被访问过，反之 Age-level-0 清零，那么 CACHE Line4 到 CACHE Line7 没有被访问过; Age-level-1 则描述 Age-level-0 识别出没有被访问过的 CACHE Line，当 Age-level-1 位清零，那么表示前半部分 CACHE Line 没有被访问过，反之 Age-level-1 位置位，那么表示后半部分的 CACHE Line 被访问过，Age-level-2 依次类推，最终会定位到最近最少被访问的 CACHE Line, 接下来以 CACHE Line4 为例子进行讲解:

![](/assets/PDB/HK/TH002429.png)

当 Age-level-0 置位，那么表示 CACHE Line4 到 CACHE Line7 没有被访问过，那么 Age-level-1 清零表示 CACHE Line4 到 CACHE Line 5 没有被访问过，最后 Age-level-2 清零表示 CACHE Line4 没有被访问过. 再如 CACHE Line0 为例进行讲解:

![](/assets/PDB/HK/TH002430.png)

当 Age-level-0 清零，那么表示 CACHE Line0 到 CACHE Line3 没有被访问过，那么 Age-level-1 清零表示 CACHE Line0 到 CACHE Line1 没有被访问过，最后 Age-level-0 清零，那么表示 CACHE Line0 没有被访问过.

![](/assets/PDB/HK/TH002431.png)

在多路 CACHE 中，需要多个年龄位进行维护，当一个 CACHE Line 被使用，那么它对应的年龄应该被设置为最大，其他 CACHE Line 的年龄按照之前的顺序排在它之后，这个过程类似于把单链表中的某个节点放到了链表表头，其余节点按之前的顺序连接在节点头之后。替换的时候总是替换年龄最小的那个 CACHE Line，也就是单链表表尾替换掉.

###### LFU(最不经常使用) 策略

LFU(Least Frequently Used) 策略将一段时间内被访问次数最少的 CACHE Line 替换出去，其原理是为每个 CACHE Line 设置一个计数器，从 0 开始计数，每访问以此对应的 CACHE Line 计数器加一。当需要替换时，将计数值最小的 CACHE Line 替换出去，同时将所有的计数器清零. 这种策略将计数周期限定在两次替换之间的时间间隔内，不能严格反应近期访问情况，新调入的块很容易被替换出去.

###### 随机替换策略

随机替换算法完全不管 CACHE 的情况，简单地根据一个随机数选择一块替换出去，随机替换算法在硬件上容易实现，且速度也比前面两种策略块。缺点就是降低了 CACHE 的命中率和 CACHE 工作效率.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

------------------------------

##### 多核架构下的 CACHE

![](/assets/PDB/HK/TH002408.png)

随着多核技术的不断普及以及摩尔定律的失效，CPU 的频率已经不是限制性能的主要因素，内存访问延时成为了系统性能的瓶颈，各大厂商在多核架构下通过增加 CACHE 的级数和 CACHE 容量，以此来加速对内存的访问。例如在 Intel 架构下，一个物理 Core 包含了两个逻辑核，两个逻辑核共用 L1 和 L2 CACHE，也就是一个物理核只有一个 L1 和 L2 CACHE。一个 CPU Socket 上面可能有一个或多个物理核，这些物理核共用 L3 CACHE，L3 CACHE 也被称为 **LLC(Last Level CACHE)**，L2 CACHE 则被称为 **MLC(Middle LeveL CACHE)**. L1 CACHE 又分为 Data CACHE 和 Instruct CACHE. 在有的架构中可能存在 4 级 CACHE，本文重点描述 3 级 CACHE 的架构.

![](/assets/PDB/HK/TH002407.png)

在 X86 架构中，CPU 访问每一级 CACHE 的延时不相同，L1 CACHE 的延时基本和指令执行的周期一致，MLC 的延时为 7ns，访问主存的时延是 100ns. 因此如果 CPU 访问的数据在 CACHE 中那么将大大提升性能.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

------------------------------

##### <span id="A80">CACHE 一致性</span>

![](/assets/PDB/HK/TH002462.png)

什么是 CACHE 一致性? 先看一个案例，之前的学习中可以知道 CPU-0 访问 Main Memory Data Block X 之后，其会被加载到 CPU-0 CACHE 的某个 CACHE Line，然后 CPU-0 就可以在 CACHE 中访问而不用去主存中访问数据. 在单核年代，CPU 对该数据的修改可以直接在 CACHE Line 中进行，然后配合适合的硬件同步机制再将 CACHE Line 中的数据同步到主存中; 但到了多核年代，CPU-0 CACHE 中缓存了主存 Data Block X, 然而 CPU-0 CACHE 同样也缓存 Data Block X, 那么 CPU-0 修改了 CACHE 中 Data Block X 的数据，同时 CPU-1 读取了 CACHE 中 Data Block X, 此时 Data Block X 在两个 CPU CACHE 的缓存的数据不一致，这种情况称为 **CACHE 一致性问题**.

![](/assets/PDB/HK/TH002463.png)

那么如何解决 CACHE 一致性问题呢? 这里通过一个例子进行讲解，当 CPU0 和 CPU1 的 CACHE Line 都缓存了主内存的 Data Block 的数据，且都为 0x1. 当 CPU0 对 Data block 执行写操作并写入 0x8, CPU0 更新了私有 CACHE Line 中的值，同时 CPU1 读取 Data Block 的值，此时 CPU1 发现 CACHE Line 命中，然后直接从私有的 CACHE Line 中读取 0x1. 从这里例子看到造成了 CPU0 和 CPU1 CACHE Line 数据不一致现象， 这样就会导致数据的观察者 (CPU/CPU/DMA) 看到数据不一致，因此维护 CACHE 一致性非常必要。维护 CACHE 一致性的关键就是需要跟踪每个 CACHE Line 的状态，并且根据读写操作和总线上相应的传输内容来更新 CACHE Line 在不同 CPU 上的 CACHE Hit 状态.

![](/assets/PDB/HK/TH002464.png)

维护 CACHE 一致性有软件和硬件两种方式，现在主流架构采用硬件维护. 在处理器中通过 CACHE 一致性协议实现，这些协议维护一个有限状态机, 根据存储器读写指令或总线上的传输内容，进行状态迁移或相应 CACHE Line 操作来维护 CACHE 一致性。CACHE 一致性协议主要分为两大类:

* 监听协议: 每个 CACHE Line 被监听或者监听其他 CACHE Line 的总线活动
* 目录协议: 全局统一管理 CACHE Line 状态

这里介绍主流的 **MESI 协议(Write-Once 总线监听协议)**, MESI 分别代表 Modify、Exclusive、Shared 和 Invalid. CACHE Line 的状态必须是其中的一种。前三种状态均是数据有效下的状态, CACHE Line 的 Flags 域包含了两个标志: **Dirty** 和 **Valid**，Dirty 置位代表该 CACHE Line 与主存 Data Block 内容不一致，Valid 置位则代表 CACHE Line 是有效的.

###### <span id="A801">MESI</span>

![](/assets/PDB/HK/TH002465.png)

* **M(Modify)**: CACHE Line 数据已经被修改，与主存中数据不一致，该数据只缓存在本地 CACHE Line 中，其他 CPU 没有缓存该副本.
* **E(Exclusive)**: CACHE Line 中的数据与主存一致，且该数据只在本地 CACHE Line 中，其他 CPU 没有缓存该副本.
* **S(Shared)**: CACHE Line 中的数据与主存一致，且多个 CACHE Line 都缓存该数据.
* **I(Invalid)**: 该 CACHE Line 没有缓存该数据.

**MESI** 在总线上的操作分为**本地读写**和**总线操作**. 当操作类型为**本地读写**时, CACHE Line 的状态指的是本地 CPU(Local CPU); 而当操作类型为**总线读写**时，CACHE Line 的状态指的是远端 CPU(Remote CPU):

* **本地读**: **本地 CPU** 读取 CACHE Line.
* **本地写**: **本地 CPU** 更新 CACHE Line.
* **总线读/远端读**: 总线监听一个来自远端 CPU 的读 CACHE 信号. 收到信号的 CPU 先检查 CACHE 是否存在该数据，然后广播应答
* **总线写/远端写**: 总线监听一个来自远端 CPU 的写 CACHE 信号. 收到信号的 CPU 先检查 CACHE 是否存在该数据，然后广播应答
* **总线更新**: 总线收到更新请求，请求其他 CPU 干活. 其他 CPU 收到请求后，若 CPU 有 CACHE 副本，则使其 CACHE Line 无效.
* **刷新**: 总线监听到刷新请求，收到请求的 CPU 将本地 CACHE Line 内容写会主内存
* **刷新到总线**: 收到该请求的 CPU 将本地 CACHE Line 发送到总线上，发起请求的 CPU 会获取该 CACHE Line 的内容.

![](/assets/PDB/HK/TH002466.png)

上图为 MESI 之间变换的状态图，**LRd** 表示本地读、**LWr** 表示本地写、**BusRd** 表示远端读或者监听到总线读请求、**BusWr** 表示远端写或监听到总线写请求、**FlushOpt** 表示把当前 CACHE Line 内容发到总线上、**Writeback** 表示将 CACHE Line 内容更新到内存. 接下来通过具体理解讲解每种状态之间变化过程:

> - [MESI 初始状态为 Invalid](#AA01)
>
> - [MESI 初始状态为 Modify](#AA02)
>
> - [MESI 初始状态为 Shared](#AA03)
>
> - [MESI 初始状态为 Exclusive](#AA04)

--------------------------------------------

###### <span id="AA01">初始状态为 Invalid</span>

![](/assets/PDB/HK/TH002467.png)

当本地 CACHE Line 的状态为 Invalid 时，其会触发本地 CPU 访问时 CACHE Miss，此时无论是本地读还是本地写，都会转换成总线读或者总线写信号，远端 CPU 的 CACHE 监听到总线信号之后会将其缓存的 CACHE Line 状态进行改变，具体改变可以从**读请求**和**写请求**进行分析:

###### 本地/远端读请求

![](/assets/PDB/HK/TH002473.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 为远端视角. 当 CPU0 发起**本地读请求 LRd** 或者 CPU1/CPU2 发起**远端读请求 RRd** 时，此时 CPU0 对应的 CACHE Line 为 Invalid，CPU1、CPU2 对应的 CACHE Line 的状态可能是 Invalid、Shared 或者 Exclusive, 那么所有 CACHE Line 的变化包含如下几种情况:

![](/assets/PDB/HK/TH002468.png)

**(1) 本地读全 Invalid**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线读 BusRd**，CPU1 和 CPU2 监听到 BusRd 之后检查 CACHE 中是否包含副本，此时 CPU1 和 CPU2 的 CACHE Line 都为 Invalid，没有包含副本, 接着 CPU1 和 CPU2 向总线发送应答信号. CPU0 广播完所有的 CPU 之后发现总线上并没有数据，那么其从内存中读取数据到本地 CACHE Line，并将 CACHE Line 的状态切换到 **Exclusive**.

![](/assets/PDB/HK/TH002469.png)

**(2) 本地读远端 Shared**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线读 BusRd**，CPU1 和 CPU2 监听到 BusRd 之后检查 CACHE 中是否包含副本，此时 CPU1 和 CPU2 检查到其缓存了副本，且 CACHE Line 的状态为 Shared，那么 CPU1/CPU2 向总线回复一个 **FlushOpt** 信号，并将 CACHE Line 的内容发送到总线上. CPU0 收到 FlushOpt 信号之后从总线上读取了数据并缓存到本地的 CACHE Line，并将 CACHE Line 的状态标记为 Shared.

![](/assets/PDB/HK/TH002470.png)

**(3) 本地读远端 Exclusive**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线读 BusRd**，CPU1 和 CPU2 监听到 BusRd 之后检查 CACHE 中是否包含副本，此时 CPU1 的 CACHE Line 都为 Invalid，那么没有包含副本，那么 CPU1 直接向总线发送应答信号; CPU2 检查到其缓存了副本，且该 CACHE Line 的状态为 Exclusive，那么 CPU2 向总线回复一个 **FlushOpt** 信号，并将 CACHE Line 的内容发送到总线上, 并将 CACHE Line 的状态切换成 Shared. CPU0 收到 FlushOpt 信号之后从总线上读取了数据并缓存到本地的 CACHE Line，并将 CACHE Line 的状态标记为 Shared.

![](/assets/PDB/HK/TH002471.png)

**(4) 本地读远端 Modify**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线读 BusRd**，CPU1 和 CPU2 监听到 BusRd 之后检查 CACHE 中是否包含副本，此时 CPU1 的 CACHE Line 都为 Invalid 没有包含副本，那么 CPU1 直接向总线发送应答信号; CPU2 检查到其缓存了副本，且该 CACHE Line 的状态为 Modify，那么 CPU2 向总线回复一个 **Writeback** 信号，并先将 CACHE Line 的内容更新到内存，然后发送到总线上, 并将 CACHE Line 的状态切换成 Shared. CPU0 收到 Writeback 信号之后从总线上读取了数据并缓存到本地的 CACHE Line，并将 CACHE Line 的状态标记为 Shared.

![](/assets/PDB/HK/TH002492.png)

**(5) 远端读本地 Invalid**: 当 CPU1 发起**远端读请求 RRd** 时，无论远端 CACHE Line 的状态如何，也无论是否产生**总线读请求 BusRd**，CPU0 监听到 BusRd 信号之后，检查其 CACHE 中并没有副本，然后直接应答总线，然后继续保持 Invalid.

###### 本地/远端写请求

![](/assets/PDB/HK/TH002472.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 为远端视角, 当 CPU0 发起**本地写请求 LRd** 或者 CPU1/CPU2 发起**远端写请求 RWr**，当本地 CACHE Line 为 Invalid 状态，远端 CACHE Line 可能是 Invalid、Modify、Exclusive 和 Shared，那么 CACHE Line 的变化包含以下几种情况:

![](/assets/PDB/HK/TH002474.png)

**(1) 本地写全 Invalid**: 当 CPU0 发起**本地写请求 LWr** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线写 BusWr**，CPU1 和 CPU2 监听到 BusWr 之后检查 CACHE 中是否包含副本，此时 CPU1 和 CPU2 的 CACHE Line 都为 Invalid，那么没有包含副本. 接着 CPU1 和 CPU2 向总线发送应答信号，并继续广播剩余的 CPU. CPU0 广播完所有的 CPU 之后发现总线上并没有数据，那么其从内存中读取数据到本地 CACHE Line，然后再修改 CACHE Line 中的数据，并将 CACHE Line 的状态切换到 **Modify**.

![](/assets/PDB/HK/TH002475.png)

**(2) 本地写远端 Shared**: 当 CPU0 发起**本地写请求 LWr** 时，发现本地 CACHE Line 的状态为无效，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线写 BusWr**，CPU1 和 CPU2 监听到 BusWr 之后检查 CACHE 中是否包含副本，此时 CPU1 和 CPU2 的 CACHE Line 都为 Shared，那么都有副本. 接着 CPU1 和 CPU2 向总线发送 FlushOpt 应答信号，并将副本的内容发送到总线，此时将 CACHE Line 状态都设置为 Invalid. CPU0 广播完所有的 CPU 之后发现总线上存在数据，那么其从总线上读取数据到本地 CACHE Line，然后修改 CACHE Line 中的数据，并将 CACHE Line 的状态切换到 **Modify**.

![](/assets/PDB/HK/TH002493.png)

**(3) 本地写远端 Exclusive**: 当 CPU0 发起**本地写请求 LWr** 时，发现本地 CACHE Line 的状态为无效，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线写 BusWr**，CPU1 和 CPU2 监听到 BusWr 之后检查 CACHE 中是否包含副本，此时 CPU1 没有包含对应的副本，那么直接应答总线. CPU2 中包含副本，且 CACHE Line 的状态为 Exclusive，接着 CPU2 向总线发送 FlushOpt 应答信号，并将副本的内容发送到总线，然后将 CACHE Line 状态都设置为 Invalid. CPU0 广播完所有的 CPU 之后发现总线上存在数据，那么其从总线上读取数据到本地 CACHE Line，然后修改 CACHE Line 中的数据，并将 CACHE Line 的状态切换到 **Modify**.

![](/assets/PDB/HK/TH002494.png)

**(4) 本地写远端 Modify**: 当 CPU0 发起**本地写请求 LWr** 时，发现本地 CACHE Line 的状态为无效，即 CACHE 中没有缓存对应的内容 CACHE Miss，那么在总线上产生一个 **总线写 BusWr**，CPU1 和 CPU2 监听到 BusWr 之后检查 CACHE 中是否包含副本，此时 CPU1 没有包含对应的副本，那么直接应答总线. CPU2 中包含副本，且 CACHE Line 的状态为 Modify，接着 CPU2 向总线发送 WriteBack 信号，并将副本的内容写入内存，再将副本发送到总线，然后将 CACHE Line 状态都设置为 Invalid. CPU0 广播完所有的 CPU 之后发现总线上存在数据，那么其从总线上读取数据到本地 CACHE Line，然后修改 CACHE Line 中的数据，并将 CACHE Line 的状态切换到 **Modify**.

![](/assets/PDB/HK/TH002495.png)

**(5) 远端写本地 Invalid**: 当 CPU1 发起**远端写请求 RWr** 时，无论远端 CACHE Line 的状态如何，也无论是否产生**总线读请求 BusWr**，CPU0 监听到 BusWr 信号之后，检查其 CACHE 中并没有副本，然后直接应答总线，然后继续保持 Invalid.

--------------------------------------------

###### <span id="AA02">初始状态为 Modify</span>

![](/assets/PDB/HK/TH002477.png)

当本地 CACHE Line 的状态是 Modify，那么说明本地 CPU 修改了 CACHE Line 的值，但没有刷新到内存里，是一份脏数据, 并且其他 CPU 没有缓存副本。. 本地或远端发起的读写请求都会概念 CACHE Line 的状态，具体变化如下场景:

###### 本地/远端读请求

![](/assets/PDB/HK/TH002478.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 为远端视角，由于 CPU0 的 CACHE Line 状态为 Modify，那么其他 CPU 没有副本。读请求会引起 CACHE Line 状态在 Modify 和 Shared 之间转换, 具体如下:

![](/assets/PDB/HK/TH002496.png)

**(1) 本地读请求**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Modify，即 CACHE 中缓存对应内容 CACHE Hit, 并且 CACHE Line 中的数据是最新的，与内存中的数据不一致，那么 CPU0 直接从本地 CACHE Line 中读取数据，并保持 CACHE Line 状态为 Modify.

![](/assets/PDB/HK/TH002479.png)

**(2) 远端读本地 Modify**: 当 CPU2 发起**本地读请求 RRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应内容 CACHE Miss, 那么在总线上产生一个**总线读 BusRd**, CPU1 监听到 BusRd 之后由于没有对应的副本，那么直接应答总线; CPU0 监听到 BusRd 之后发现具有对应的 CACHE Line 副本，且此时 CPU0 CACHE Line 的状态为 Modify，那么其向总线发送一个 Writeback 信号，同时将 CACHE Line 的数据发送到总线，并且将数据也写会到内存，最后将 CPU0 CACHE Line 状态设置为 Shared; CPU2 收到总线 Writeback 信号之后从总线上获得数据，并存储在 CPU2 的 CACHE Line，最后将 CACHE Line 状态设置为 Shared.

###### 本地/总线写请求

![](/assets/PDB/HK/TH002480.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 为远端视角，由于 CPU0 的 CACHE Line 状态为 Modify，那么其他 CPU 没有副本。写请求会引起 CACHE Line 状态在 Invalid 和 Modify 之间转换, 具体场景如下:

![](/assets/PDB/HK/TH002497.png)

**(1) 本地写请求**: 当 CPU0 发起**本地写请求 LWr** 时，发现本地 CACHE Line 的状态为 Modify，即 CACHE 中缓存对应内容 CACHE Hit, 并且 CACHE Line 中的数据是最新的，与内存中的数据不一致，那么 CPU0 直接更新本地 CACHE Line 中数据，并保持 CACHE Line 状态为 Modify.

![](/assets/PDB/HK/TH002481.png)

**(2) 远端写本地 Modify**: 当 CPU2 发起**本地写请求 RRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应内容 CACHE Miss, 那么在总线上产生一个**总线写 BusWr**, CPU1 监听到 BusWr 之后由于没有对应的副本，那么直接应答总线; CPU0 监听到 BusWr 之后发现具有对应的 CACHE Line 副本，且此时 CPU0 CACHE Line 的状态为 Modify，那么其向总线发送一个 Writeback 信号，同时将 CACHE Line 的数据发送到总线，并且将数据也写会到内存，最后将 CPU0 CACHE Line 状态设置为 Invalid; CPU2 收到总线 Writeback 信号之后从总线上获得数据，并存储在 CPU2 的 CACHE Line，接着更新 CACHE Line 中的内容，最后将 CACHE Line 状态设置为 Modify.

--------------------------------------------

###### <span id="AA03">初始状态为 Shared</span>

![](/assets/PDB/HK/TH002482.png)

当本地 CACHE Line 的初始状态为 Shared，那么说明其他 CPU 也缓存了该副本，且 CACHE Line 的状态可能是 Invalid 或者 Shared. 此时无论是本地读写还是远端读写，都会改变 CACHE Line 的状态，具体改变可以从**读请求**和**写请求**场景进行分析:

###### 本地/远端读请求

![](/assets/PDB/HK/TH002498.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 远端视角. 当 CPU0 发起**本地读请求 LRd**或者 CPU1/CPU2 发起**远端读请求 RRd**，当本地 CACHE Line 的状态为 Shared 状态，远端 CACHE Line 的状态可能是 Shared 或 Invalid，那么 CACHE Line 的变化包括如下几种场景:

![](/assets/PDB/HK/TH002483.png)

**(1) 本地读请求**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Shared，即 CACHE 中有缓存对应内容 CACHE Hit, 其他 CPU 也有相应的副本，且所有的副本与内存上的数据是一致的，因此本地 CACHE Line 的状态保持 Shared，不会向总线发起 BusRd 信号，而是直接从 CACHE Line 中读取数据.

![](/assets/PDB/HK/TH002484.png)

**(2) 远端写请求**: 当 CPU1 发起**远端读请求 RRd** 时，发现其 CACHE Line 的状态为 Invalid，即 CACHE 中有没有缓存对应内容 CACHE Miss, 那么在总线上产生一个**总线读请求 BusRd**，CPU0 监听到 BusRd 信号之后，发现其具有副本且 CACHE Line 状态为 Shared，那么直接应答一个 FlushOpt 信号，并将 CACHE Line 的内存发送到总线上，其他 CACHE Line 为 Shared 的也会做同样操作; CPU1 收到 FlushOpt 信号之后，从总线上读取数据到自己的 CACHE Line，并将 CACHE Line 信号更改为 Shared.

###### 本地/远端写请求

![](/assets/PDB/HK/TH002499.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 远端视角. 当 CPU0 发起**本地写请求 LWr**或者 CPU1/CPU2 发起**远端写请求 RWr**，当本地 CACHE Line 的状态为 Shared 状态，远端 CACHE Line 的状态可能是 Shared 或 Invalid，那么 CACHE Line 的变化包括如下几种场景:

![](/assets/PDB/HK/TH002485.png)

**(1) 本地写请求**: 当 CPU0 发起**本地写请求 LWr** 时，发现本地 CACHE Line 的状态为 Shared，即 CACHE 中有缓存对应内容 CACHE Hit, 其他 CPU 也有相应的副本，且所有的副本与内存上的数据是一致的，CPU0 向总线产生一个**总线写 BusWr**, 其他 CPU 监听到 BusWr 之后检查是否包含对应的副本，如果有则将对应的 CACHE Line 状态设置为 Invalid，并回应一个 FlushOpt 信号. CPU0 收到 FlushOpt 应答之后直接修改本地 CACHE Line 的内容，并将 CACHE Line 的状态修改为 Modify.

![](/assets/PDB/HK/TH002486.png)

**(2) 远端写请求**: 当 CPU1 发起**远端写请求 RWr** 时，发现其 CACHE Line 的状态为 Shared，即 CACHE 中有缓存对应内容 CACHE Hit, 其他 CPU 也有相应的副本，且所有的副本与内存上的数据是一致的，CPU1 向总线产生一个**总线写 BusWr**, CPU0 监听到 BusWr 之后检查包含对应的副本，CPU0 则将对应的 CACHE Line 状态设置为 Invalid，并回应一个 FlushOpt 信号. CPU2 监听到 BusWr 之后检查不包含对应的副本，直接应答总线. CPU1 收到 FlushOpt 应答之后直接修改其 CACHE Line 的内容，并将 CACHE Line 的状态修改为 Modify.

--------------------------------------------

###### <span id="AA04">初始状态为 Exclusive</span>

![](/assets/PDB/HK/TH002487.png)

当本地 CACHE Line 的状态为 Exclusive，那么说明其他 CPU 并没有该 CACHE Line 的副本，并且本地 CACHE Line 的内容和内存中的内存是一致的. 此时无论是本地读写还是远端读写，都会改变 CACHE Line 的状态，具体改变可以从**读请求**和**写请求**场景进行分析:

###### 本地/远端读请求

![](/assets/PDB/HK/TH002500.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 远端视角. 当 CPU0 发起**本地读请求 LRd**或者 CPU1/CPU2 发起**远端读请求 RRd**，当本地 CACHE Line 的状态为 Exclusive 状态，远端 CACHE Line 的状态是 Invalid，那么 CACHE Line 的变化包括如下几种场景:

![](/assets/PDB/HK/TH002488.png)

**(1) 本地读请求**: 当 CPU0 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Exclusive，即 CACHE 中有缓存对应内容 CACHE Hit, 其他 CPU 没有有相应的副本，且 CACHE Line 与内存上的数据是一致的，因此本地 CACHE Line 的状态保持 Exclusive，不会向总线发起 BusRd 信号，而是直接从 CACHE Line 中读取数据.

![](/assets/PDB/HK/TH002489.png)

**(2) 远端读请求**: 当 CPU1 发起**本地读请求 LRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应内容 CACHE Miss, 那么产生一个**总线读请求 BusRd**. CPU0 监听到 BusRd 信号之后，检查其 CACHE 中存在副本，那么向总线发送 FlushOpt 信号并将 CACHE Line 内容发送到总线上，然后将其 CACHE Line 的状态切换成 Shared; CPU2 收到 BusRd 信号之后，检查其没有对应的副本，那么直接应答总线; CPU1 收到 FlushOpt 信号之后从总线上读取内容到本地的 CACHE Line，然后将 CACHE Line 状态设置为 Shared.

###### 本地/远端写请求

![](/assets/PDB/HK/TH002501.png)

假设系统有 3 个 CPU，分别是 CPU0、CPU1 和 CPU2，并且 CPU0 为本地视角，CPU1 和 CPU2 远端视角. 当 CPU0 发起**本地写请求 LWr**或者 CPU1/CPU2 发起**远端写请求 RWr**，当本地 CACHE Line 的状态为 Exclusive 状态，远端 CACHE Line 的状态是 Invalid，那么 CACHE Line 的变化包括如下几种场景:

![](/assets/PDB/HK/TH002490.png)

**(1) 本地写请求**: 当 CPU0 发起**本地写请求 LRd** 时，发现本地 CACHE Line 的状态为 Exclusive，即 CACHE 中有缓存对应内容 CACHE Hit, 其他 CPU 没有有相应的副本，且 CACHE Line 与内存上的数据是一致的，因此直接修改 CACHE Line 的内容，并将 CACHE Line 的状态切换为 Modify.

![](/assets/PDB/HK/TH002491.png)

**(2) 远端写请求**: 当 CPU1 发起**本地写请求 LRd** 时，发现本地 CACHE Line 的状态为 Invalid，即 CACHE 中没有缓存对应内容 CACHE Miss, 那么产生一个**总线写请求 BusWr**. CPU0 监听到 BusWr 信号之后，检查其 CACHE 中存在副本，那么向总线发送 FlushOpt 信号并将 CACHE Line 内容发送到总线上，然后将其 CACHE Line 的状态切换成 Invalid; CPU2 收到 BusWr 信号之后，检查其没有对应的副本，那么直接应答总线; CPU1 收到 FlushOpt 信号之后从总线上读取内容到本地的 CACHE Line，然后修改 CACHE Line 内容，并将 CACHE Line 状态设置为 Modify.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------



