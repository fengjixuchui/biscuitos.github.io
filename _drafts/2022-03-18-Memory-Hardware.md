---
layout: post
title:  "Memory Hardware Common Knowledge"
date:   2022-03-18 12:00:00 +0800
categories: [HW]
excerpt: Memory Hardware.
tags:
  - Memory
---

![](/assets/PDB/BiscuitOS/kernel/IND00000L0.PNG)

![](/assets/PDB/RPI/RPI100100.png)

#### 目录

> - [Memory Hardware 基础介绍](#A)
>
>   - [软件角度看内存架构](#A0)
>
>   - [地址总数/数据总线/控制总线](#A1)
>
>   - [物理内存/物理地址](#A2)
>
>   - [虚拟内存/虚拟地址](#A3)
>
> - Memory Hardware Layout
>
>   - X86 Architecture Memory Layout
>
> - [附录/捐赠](#Z0)

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="A"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000Q.jpg)

#### Memory Hardware 基础介绍

![](/assets/PDB/HK/TH001438.png)

内存作为计算机架构运行的必要硬件设备之一被开发者熟知，作为软件开发者更多认识的是内存的大小、NUMA NODE、Zone 等概念，而对于硬件开发者来说内存就是内存条、DRAM、PMEM 等硬件设备。因此从不同角度对内存都有不同的解读，本文用于帮助软件开发者和硬件开发者打破认知防线，通熟易懂的语言将内存进行讲解，以便开发者在日后的开发中方便使用。本文分作四个模块进行讲解，第一部分对与内存相关的术语进行图文并茂的讲解，第二个部分从整体架构角度对内存进行讲解，第三部分则是对软硬件工具的实践来认知内存，第四部分则是内存未来趋势讨论. 本文以 X86 架构进行讲解, 其他架构举一反三:

> - [软件角度看内存架构](#A0)
>
> - [地址总数/数据总线/控制总线](#A1)
>
> - [物理内存/物理地址](#A2)
>
> - [虚拟内存/虚拟地址](#A3)
>
> - [逻辑地址]()
>
> - [Register 通用寄存器]()
>
> - [Data Cache 数据缓存]()
>
> - [Instructure Cache 指令缓存]()
>
> - [L1 Cache]()
>
> - [L2 Cache]()
>
> - [L3 Cache]()
>
> - [TLB]()
>
> - [Page-Structure Cache]()
>
> - [Main Memory]()
>
> - [page cache]()
>
> - [Buffer]()
>
> - [Stack]()
>
> - [Heap]()
>
> - [MMAP Virtual Area]()
>
> - [Segment]()
>
> - [Code Segment]()
>
> - [Data Segment]()
>
> - [BSS Segment]()

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="A0"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000T.jpg)

#### 软件角度看内存架构

![](/assets/PDB/HK/TH001434.png)

公元前 5 世纪中国人发明了算盘，用于计算生意贸易的结算，算盘相当于是最早的计算机。随着科技不断的发展，1946 年冯诺依曼提出了计算机的基本原理 **存储程序和程序控制**，以此奠定了现代计算机的基础，人们称这种架构为冯诺依曼架构 (Von Neumann Architecture)。在冯诺依曼架构中提出了由二进制代替十进制的思想，采用存储程序思想，并且将计算机逻辑分为控制器、运算器、存储器、输入设备、输出设备五大部分，其中控制器与运算器组成了大家熟知的 CPU, 存储器一般为内存，磁盘也属于存储器，不过磁盘和内存的存储形式有所不同。

![](/assets/PDB/HK/TH001435.png)

在冯诺依曼架构中，程序在执行前需要将程序和数据放入到存储器中 (PC 上是内存)，当程序执行时把要执行的程序和要处理的数据顺序从存储器中取出指令一条一条的执行，称为顺序执行程序。冯诺依曼架构的核心是运算器为核心，但随着科技不断发展，现在计算机的核心以存储器为核心。由于冯诺依曼架构将数据和指令统一放在存储器中，并且由于顺序执行程序，导致指令的吞吐量遇到瓶颈，因此提出了著名的哈弗架构 (Harvard architecture), 哈弗架构设计的特点是指令存储器和数据存储器是两个独立的存储器，每个存储器独立编址、独立访问. 哈弗结构减轻程序运行时的存放瓶颈。

![](/assets/PDB/HK/TH001436.png)

随着计算不断发展，两种架构相互补齐不足相互发展，最终通用计算机体系结构发展如上图。控制器和计算器组合成 CPU，CPU 中包含了寄存器，寄存器是离 CPU 最近存储器，提供最快速度的数据存储，用于暂时提供 CPU 数据存储能力。CPU 和主内存之间存在 CPU CACAHE Memory 存储器, 用于提供高速小容量数据存储能力以此加快数据访问。主存储器 RAM Main Memory 提供超大容量低速数据存储能力以此存储大部分的数据。外设存储 Storage 可有不同的磁盘设备组成，用于提供持久数据存储能力，磁盘外设包括: floppy 软盘、CD-ROM、SATA 硬盘、SSD 硬盘、ESSD 云盘等设备.

![](/assets/PDB/HK/TH001437.png)

一个程序的生命周期与存储器之间的关系如上图, 源程序经过编译之后生成可执行的二进制文件，二进制文件一般存储到磁盘外设中，当程序在执行的时候，程序的代码段、数据段、BSS 段等数据被拷贝到 Main Memory 主内存中，另外程序运行时候的 heap 堆、Stack 堆栈也会占用主内存的一部分空间。接着 CPU 将要执行的指令和数据准备从主存储中加载到 CPU 中运行，此时 Cache 利用局部行原理将指令和数据相关的一部分内存缓存到 Cache 中，以此加快 CPU 获得下一条指令或数据的速度。Cache 缓存完内容之后，将 CPU 需要执行的指令和数据加载到寄存器中，接下来 CPU 执行指令和处理数据，期间产生的数据和最终产生的数据都存储在寄存器中。待 CPU 执行完指令之后，如果 CPU 需要将计算结果写入到主内存，那么系统首先检查写入的内存是否已经缓存到 Cache 中，如果已经缓存到 Cache 里，那么系统将寄存器中数据拷贝到 Cache 中即可; 反之如果写入的内存没有缓存在 Cache 中，那么系统将寄存器中的内存直接写入到主内存中，然后将主内存中内容缓存中 Cache 中，而 Cache 中原有的内容则提前同步到主内存中。最后如果执行的程序需要将数据写入到磁盘文件上，那么主内存中的数据会在合适的时机同步到磁盘文件上. 待程序执行完毕之后，其 heap/Stack/MMAP 占用的内存将被释放回收。

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="A1"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000L.jpg)

#### 地址总线/数据总线/控制总线

![](/assets/PDB/HK/TH001440.png)

CPU 与内存 (主存储器) 之间的相互操作通过总线来控制，从软件角度来看 CPU 通过地址总线 Address Bus、数据总线 Data Bus 和控制总线 Control Bus 与内存(主存储器) 相离; 但从硬件角度来看，CPU 不是直接通过地址总线、数据总线和控制总线相连，中间还涉及内存控制器和北桥等硬件设备。本节从软件角度介绍三根总线。

-------------------------------------------

###### 地址总线

![](/assets/PDB/HK/TH001442.png)

从软件角度来看，**地址总线**(Address Bus)是寻址设备地址空间的总线，所谓**寻址**指的是 CPU 向地址总线写入一个地址来查找指定设备地址空间。所谓**地址空间**是设备用来存储、控制、配置的区域，例如主存储的地址空间是用于存储数据的区域，又如 PCI 配置空间等。另外 CPU 向地址总线写入的地址称为**物理地址**(Physical Address)，地址总线上可以挂载多种设备，例如主存储器、CMOS、中断控制器、DMA 控制器等，CPU 通过物理地址和地址总线就可以访问到外设。**总线地址**(Bus Address)是地址总线为每个设备地址空间的编址，从软件角度来看总线地址和物理地址是等同的，但从硬件角度来看总线地址和物理地址不等同。

![](/assets/PDB/HK/TH001443.png)

上图是从软件角度看地址总线上每个设备地址空间的编址，物理地址寻址的空间是一块线性的空间，各设备都有独立的物理地址范围。可以看到第一块物理内存(主存储器) 的物理地址范围是 \[0x00001000, 0x0009fc00), 第二块物理内存(主存储器) 的物理地址范围是 \[0x00100000, 0x1ffde000). 另外可以看出其他设备地址空间编址，例如 PCI Bus 0000:00 的物理地址范围是 \[0x000a000, 0x000e0000).

![](/assets/PDB/HK/TH001445.png)

从软件角度来看，地址总线构建一块连续的线性空间，并且可以通过物理地址寻址地址总线上设备的地址空间。将地址总线的线性空间都拆分成 PAGE_SIZE 字节长度的区域，并为每个区域按从底地址到高地址进行编号，那这个编号称为**页帧号**(Frame Number)。主存储器(内存)是地址总线上的一个设备，其存储空间由一个字节长度的内存单元构成，物理地址可以对主存储器的每个内存单元进行寻址，也就是每个内存单元都有唯一的物理地址。将主存储器的 PAGE_SIZE 个内存单元看成一个整体，这个内存区域称为**物理页**(Physical Page), 物理页对应的页帧号称为**物理页帧号**(Physical Page Frame Number, 简称 PFN), 那么其关系为: PFN = Phys >> PAGE_SHIFT.

![](/assets/PDB/HK/TH001439.png)

地址总线的根数决定了 CPU 的寻址能力，例如 32 根地址总线可以寻址 \[0,4G) 范围的物理地址, CPU 不能寻址超过地址总线寻址能力的设备, 例如在 32 根地址总线的架构中，一根 8Gig 内存条最多只能寻址 4G。32 位系统/64 位系统描述的是计算机的位宽，其指定的是一个时钟周期内所能传送数据的位数，因此其与数据总线的宽度有关，与地址总线的根数无关，例如 64 位系统其地址总线通常为 48 根.

---------------------------------------------

###### 数据总线

----------------------------------------------

###### 控制总线

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="A2"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000W.jpg)

#### 物理内存/物理地址

![](/assets/PDB/HK/TH001442.png)

从软件角度来看，**物理内存**(Physical Memory)就是主存储器的存储空间，从硬件角度来看，物理内存等同于内存条。物理内存的作用是为系统提供高速的存储空间。CPU 通过地址总线、数据总线和控制总线与其他设备相连，其中地址总线用于寻址总线上设备的地址空间，主存储器也是其中的一个设备，因此 CPU 可以通过地址总线寻址主存储器。另外 CPU 向地址总线写入的地址称为**物理地址**(Physical Address)，物理地址可以在地址总线上寻址设备的地址空间，所谓的设备的地址空间可能是存储空间，也可能是配置空间等。

![](/assets/PDB/HK/TH001444.png)

从软件角度来看，主存储器的存储空间是一块连续平坦的空间，那么将其存储空间以一个字节为内存单元，从低到高的顺序进行编址，该编址是内存单元在主存储器内的偏移地址。地址总线使用一段物理地址对主存储器的存储空间进行编址，如果主存储器是地址总线的第一个设备，那么第一个物理地址可寻址主存储器的第一个内存单元地址，依次类推; 反之如果主内存不是地址总线上的第一个设备，那么第 N 个物理地址寻址主存储器第一个内存单元，依次类推。结合物理内存的定义可知: 物理地址可以寻址物理内存，但物理内存的地址不包括所有的物理地址。

![](/assets/PDB/HK/TH001443.png)

上图是从软件角度看地址总线上每个设备地址空间的编址，物理地址寻址的空间是一块线性的空间，各设备都有独立的物理地址范围。可以看到第一块物理内存(主存储器) 的物理地址范围是 \[0x00001000, 0x0009fc00), 第二块物理内存(主存储器) 的物理地址范围是 \[0x00100000, 0x1ffde000). 另外可以看出其他设备地址空间编址，例如 PCI Bus 0000:00 的物理地址范围是 \[0x000a000, 0x000e0000).

![](/assets/PDB/HK/TH001445.png)

从软件角度来看，地址总线构建一块连续的线性空间，并且可以通过物理地址寻址地址总线上设备的地址空间。对于主存储器的地址空间，其由一个个内存单元组成，每个内存单元长度为一字节，并且内存单元可以通过物理地址进行寻址，因此每个内存单元都有一个物理地址。如果将 PAGE_SIZE 个内存单元看做一个内存区域，那么这个内存区域称为 **物理页**(Physical Page)，另外如果将地址总线的线性空间都拆分成 PAGE_SIZE 字节长度的区域，并为每个区域按从底地址到高地址进行编号，那么将这个编号称为**页帧号**(Frame Number), 由于物理页的长度也是 PAGE_SIZE 个字节，那么把物理页(主存储器) 的页帧号称为**物理页帧号**(Physical Page Frame Number)，那么物理内存和物理页帧号之间的关系: PFN = PHYS >> PAGE_SHIFT.

![](/assets/PDB/HK/TH001439.png)

物理内存的大小从不同的角度决定条件不同，从硬件角度看物理内存的大小由内存条的大小直接决定，但从软件角度来看物理内存首先有地址总线的根数限制，一般情况下 32 根地址总线最多可寻址 4G 的地址空间，那么决定了物理内存最大不超过 4G，其二是地址总线空间的布局导致物理内存只能部分线性区域给物理内存使用，因此物理内存在地址总线上被拆分成多块.

###### 物理内存和虚拟内存

![](/assets/PDB/HK/TH001447.png)

计算机硬件架构中存在一种硬件 MMU(Memory Management Unit), 通常称为内存管理单元，有时也称为分页内存管理单元 PMMU(Paged memory management unit), 它是一种负责处理 CPU 的内存访问请求的计算机硬件。MMU 主要包含: 虚实地址翻译、访问权限控制。另外在计算机中存在实时模式和保护模式，当 CPU 处在实时模式下，CPU 看到的内存就是地址总线上的物理内存，那么 CPU 可以通过物理地址直接访问物理内存; 当计算机处在保护模式，MMU 的分页功能便随之启动，此时 CPU 看到的内存是一块连续的线性空间，那么称这块空间为**虚拟内存**, CPU 此时使用称为**虚拟地址**的地址来访问虚拟内存。虚拟内存的大小与计算机的位宽有关，例如 32 位系统虚拟内存的范围是 \[0, 4G), 而 64 位系统虚拟内存的范围是 \[0, 2^64). 虚拟内存的特点就是连续且范围巨大。

![](/assets/PDB/HK/HK000993.png)

**页表**是一块长度为 PAGE_SIZE 的物理内存, 其被划分为指定长度的 Entry，Entry 内记录了下一级页表的物理地址或者物理页的物理地址。MMU 将虚拟地址划分为多个区域，高地址区域称为页目录偏移区域(Directory), 其对应的页表称为 Page Directory. 中间页表偏移区域称为页表偏移(Table), 其对应的页表称为 Page Table，最低地址区域称为页内偏移。虚拟地址 Directory 区域对应 Page Directory 页表的指定 Entry，该 Entry 称为 PDE(Page Directiry Entry), PDE 里记录了 Page Table 页表的物理地址; 同理虚拟地址 Table 区域对应 Page Table 页表指定的 Entry，该 Entry 称为 PTE(Page Table Entry), PTE 记录了物理页的起始物理地址。虚拟地址 Offset 区域则结合 PTE 记录的物理页的起始物理地址，就可以计算处虚拟地址对应的物理地址。

![](/assets/PDB/HK/HK000996.png)

在 X86 架构中，系统使用 CR3 寄存器存储 Page Table 页表的起始物理地址，然后将虚拟地址 VA 向右偏移 PGD_SHIFT 位之后获得了虚拟地址的 Directory 区域, 结合 Page Directory 就可以获得对应的 PDE, 此时 PDE 内记录了 Page Table 页表的起始物理地址。

![](/assets/PDB/HK/TH001448.png)

在获得 PDE 之后，将虚拟地址 VA 向右偏移 PTE_SHIFT 位并屏蔽 Directory 区域之后获得了虚拟地址的 Table 区域，结合 Page Table 既可以获得对应的 PTE，此时 PTE 内记录了物理页的起始物理地址。

![](/assets/PDB/HK/HK000993.png)

在获得 PTE 之后，将虚拟地址 VA 的低 PAGE_SHIFT 位区域隔离出来就可以获得 Offset 区域，结合物理页的起始物理地址，就可以在物理页内找到一个物理地址，此地址就是虚拟地址映射的物理地址。

![](/assets/PDB/HK/TH001449.png)

MMU 通过页表将虚拟内存与物理内存进行映射，对已经建立页表的虚拟内存，CPU 访问虚拟地址时 MMU 自动将虚拟地址转译成物理地址，然后访问到真实的物理内存。对于没有建立页表的虚拟内存，CPU 访问是会触发缺页异常，CPU 中断程序的执行进入缺页异常处理函数。在缺页移除处理函数里，内核根据虚拟地址从 CR3 开始遍历页表，依次找到对应的 PDE 和 PTE，如果 Page Directory 或者 Page Table 页表不存在，那么系统同样分配一个物理页作为页表，然后分别填充 PDE 和 PTE 的内容。最后新分配一个物理页，然后将物理页的页帧号填入到 PTE 中。缺页中断处理完上面的动作之后就进行中断返回，CPU 再次将执行权归还给原进程，CPU 再次访问虚拟地址，由于此时页表已经建立，那么 MMU 透明的进行地址转义并访问到物理内存。当进程不再运行时，系统在回收进程的虚拟内存时，将已经建立的页表的虚拟地址，内核将虚拟地址对应的页表 Entry 内容清零，最后系统回收对应的物理内存。

###### 物理内存生命周期

![](/assets/PDB/HK/HK000427.png)

在 X86 架构的机器上，系统在上电之前将内存条被插入到内存插槽，系统首先启动 BIOS(Basic Input Output System)，BIOS 根据 CMOS/BDA/EBDA 中的信息信息进行硬件初始化，将系统初始化到一个已知状态。CMOS(Complementary Metal Oxide Semiconductor) 是电脑主板上的一块可读写的 ROM 芯片，存储着 BIOS 配置信息，其中也包含着物理内存相关的信息，BIOS 通过外设 IO 地址空间可以访问 BIOS，通过该通路获得了不同物理地址范围内可用物理内存的信息; BDA(BIOS Data Area) 是 RAM 里的一段数据，主要用于 BIOS 管理外设和资源，BIOS 将从 COMS 中获得的内存信息存储到 BDA 指定区域以便后续使用; EBDA(Extended BIOS Data Area) 同 BDA 一样，其也包含了一部分内存信息。BIOS 在硬件初始化完毕之后探测到所有的可用物理内存之后，并构建 BIOS 中断向量表 IVT(Interrupt Vector Table), 并提供多个向量给早期的内核使用。

![](/assets/PDB/HK/TH001450.png)

BIOS 在完成自己的使命之后将控制权移交给早期的内核，此时内核处于实时模式，CPU 直接通过物理地址访问物理内存。当内核初始化到一定阶段进入保护模式，内核临时为部分的内核空间虚拟内存建立页表并映射物理内存，并出现了大块连续的虚拟内存映射到大块连续的物理内存上，因此这部分区域称为线性映射区域，这部分区域只需简单的线性关系就可以获得虚拟内存和物理内存的映射关系，无需通过查页表获得。

![](/assets/PDB/HK/HK000320.png)

内核继续初始化，内核根据中断向量表 IVT 获得了系统可用物理内存的信息，并用这些信息构建了 E820 表，E820 表有多个 Entry 组成，每个 Entry 用于记录一段物理空间的内存信息，如果某段物理区域是内存，那么对应的 E820 Entry 就会将这段区域标记为内存，反之不是物理内存则标记为 Reserved。通过 E820 表可以知道物理内存在物理空间的布局。早期的 E820 表信息来自 BIOS IVT 中断向量表，那么称该表为 BIOS-E820 表。随着内核不断初始化，内核从 CMDLINE 中获得开发者对内存布局的规划, 开发者可以将指定范围的物理内存进行预留，预留之后的物理内存对系统不可见，并将 BIOS-E820 表进行改造。

![](/assets/PDB/HK/TH001451.png)

内核初始化到一定阶段之后将物理内存布局信息 E820 表传递给 MEMBLOCK 物理内存管理器，其作为早期的物理内存管理器，将内存分作两部分，一部分为 memory 即可用内存，另外一部分为 reserved 即为预留内存，MEMBLOCK 使用区域的概念管理两种内存。对于预留内存可以是已经在使用的内存以及 CMDLINE 预留的内存，MEMBLOCK 将物理内存管理起来，以便供早期的内存分配需求，由于 MEMBLOCK 管理的物理内存都是已经内核空间虚拟内存建立页表的物理内存，因此 MEMBLOCK 分配器的物理内存内核可以直接使用(无需建立页表)。

![](/assets/PDB/HK/TH001452.png)

Linux 支持 Flat memory model、Discontiguous memory model 和 SPARSE memory model 三种内存模型。在平坦模式(Flat Model)下, 物理内存空间是一块平坦连续的空间，内核使用 struct page 数据结构数组 mem_map[], mem_map[] 数组的每个成员按顺序映射物理页，因此 page、PHY 和 PFN 就建立了独一无二的映射关系. 平坦模型虽然简单高效但存在一个缺点，对于空洞的区域还是照样分配 struct page 进行绑定，这会造成系统内存浪费.

![](/assets/PDB/HK/TH001453.png)

在稀疏模型(SPARSE Model)下，内核采用物理内存拆分为 SECTION_SIZE 大小的 SECTION 区域，那么物理内存被划分成多个 SECTION 区域，每个 SECTION 区域使用一个 struct mem_section 数据结构进行维护，其成员 section_mem_map 指向一个 struct page 数组，数组中的成员与该 SECTION 内的物理页一一对应。SPARSE 使用一个 struct mem_section 数组 SECTION_ROOT 作为根节点与每个 SECTION 的 struct mem_section 构成树型布局，因此 SPARSE 模型构建了 page、mem_section、PHY 和 PFN 建立了独一无二的映射关系。稀疏模型让只有存在物理内存的区域与 struct page 进行绑定，而对于空洞的区域可以在热插内存时再与 struct page 进行绑定，很好的节省了系统内存开销。Discontiguous memory model 已经过时不进行讲解.

![](/assets/PDB/HK/TH001454.png)

内核根据用途将物理内存细分为不同的区域 (Zone), ZONE_DMA 为适用于 DMA 的内存域，该区域的长度依赖于处理器类型。在 IA32 架构中一般标记为 16MiB，这是由古老的 ISA 设备强加的边界，但现代计算机不受这一限制; ZONE_DMA32 适用于 32 位地址总线寻址和适用于 DMA 的内存域，显然 64 位系统上两种 DMA 才有区别，IA32 架构中 ZONE_DMA32 为空, AMD64 架构上 ZONE_DMA32 区域可能从 0 到 4Gig; ZONE_NORMAL 区域是可以直接映射到内核空间的普通内存区域，架构上保证都会存在 ZONE_NORMAL, 但无法保证该区域对应实际的物理内存。ZONE_HIGH 区域为超出内核空间直接映射区域的物理内存，在 IA32 架构中内核空间可以直接映射的区域只有 896MiB，那么超出 896MiB 的物理内存都属于 ZONE_HIGH，另外对于 AMD64 架构则不需要 ZONE_HIGH; 另外内核还定义了 ZONE_MOVABLE 区域，在防止物理内存碎片机制中需要使用该内存区域。 

![](/assets/PDB/RPI/RPI000827.png)

内核继续初始化，MEMBLOCK 内存分配器将可用的物理内存区域传递给 Buddy 内存分配器，Buddy 分配器将接受到的可用物理内存按 PAGE_SIZE 为基础单位进行管理，并与 struct page 进行绑定和初始化。Buddy 分配器在接收物理页的时候会将连续相连的物理页合并成一个大的复合页，**复合页**是将多个 struct page 组合成一个 struct page 的物理页集合，此时复合页根据其物理页的数量划分为 2 的幂阶，不同阶的复合页维护在不同的 free_area[] 链表上，Buddy 一共维护了 MAX_ORDER 个 free_area 链表。此过程也是 Buddy 内存分配器的初始化过程，当 Buddy 初始化完毕之后会发现高阶的 free_area 链表上维护很多高阶复合页，此时 MEMBLOCK 分配器已经完成了使命将停止使用，接下来系统分配物理内存将由 Buddy 分配器负责。

![](/assets/PDB/RPI/RPI000835.png)
![](/assets/PDB/RPI/RPI000836.png)
![](/assets/PDB/RPI/RPI000837.png)
![](/assets/PDB/RPI/RPI000838.png)

内核在初始化的过程中, 内核为不同的 ZONE 都分配一个 Buddy 分配器，那么每个 Zone 就有各自的 free_area 链表。当系统需要分配物理内存时，Buddy 分配器从指定的 ZONE 的 free_area 链表上查找可用复合页，如果有那么将复合页从链表中移除并返回给调用者; 反之如果 free_area 链表中没有可用的复合页时，Buddy 分配器就从更高阶的 free_area 链表上查找可用的复合页，直到找到一个可用的复合页, 找到之后 Buddy 分配器将复合页一分为二，其中一个加入低阶的 free_area，另外一个如果满足需求就直接返回给调用者，如果大于需求的物理内存，那么 Buddy 分配器继续将复合页一分为二，以此类推直到找到合适的复合页为止。当使用者不再使用物理内存时，将物理内存归还给 Buddy 内存分配器，Buddy 分配器首先在复合页对应阶的 free_area 链表中查看其兄弟复合页是否空闲，如果空闲那么将其兄弟从当前 free_area 链表中移除，然后合并成一个更高阶的复合页, 以此类推直到没有可以合并的兄弟复合页为止。通过 Buddy 算法可以保持 Buddy 分配器中大块连续的物理内存, 从 ZONE_DMA32 和 ZONE_NORMAL 区域的物理页由于已经和内核空间线性映射，因此 Buddy 分配器从这些区域分配的内存存在: 物理地址和虚拟地址连续的特点

![](/assets/PDB/RPI/RPI000908.png)

由于内核高频使用单个物理页，如果单个物理页频繁在 Buddy 分配器进行分配回收势必影响性能，那么内核使用 PCP 分配器用于管理冷热物理链表，每个 ZONE 为每个 CPU 维护了一个 pageset 链表，链表上维护单个物理页且热的物理页位于链表的前端，而相对冷的物理页位于链表的尾部，PCP 分配器维护一定数量的独立物理页，当 PCP 分配器维护的物理页数量小于某个值时，PCP 分配器从 Buddy 分配器一次性分配多个独立的物理页进行维护; 反之当 PCP 分配器中维护的物理页超过一定数量之后，PCP 分配器将部分冷的物理页归还给 Buddy 分配器。系统中有了 PCP 分配器的存在大大提供了物理内存的分配效率和性能。

![](/assets/PDB/RPI/TB000021.png)

在内核中高频使用小块内存，其粒度远远小于 PAGE_SIZE，有时就几个字节，为了向内核提供小粒度的内存，内核提供了 SLAB/SLOB/SLUB 内存分配器，其从 Buddy 分配器中获得一个或多个物理页，且这些物理页都是直接映射内核空间的，也就是内核空间的虚拟地址已经和这些物理页建立了页表，由于线性映射的缘故 Buddy 分配器分配这种物理页之后可以直接知道其对应的虚拟地址。SLAB 分配器在获得这类物理页之后将其划分成两部分，一部分被划分为同等长度的多个内存区域称为 object，另外一部分用于管理 object 使用的 slab 区域，slab 区域内使用 bitmap 记录了 object 的使用情况，另外 object 存储着下一个 object 的地址，这样 object 就形成了一个链表，object 的长度就是 slab 提供的长度。当 SLAB 分配器分配一个 object 时，其从 slab 的 s_mem 获得一个可用的 object，然后将其从 object 链表中移除，并将 s_mem 指向下一个空闲的 object，并将获得的 object 返回给调用者; 当调用者使用完这个 object 之后，再次获得 slab 的 s_mem，并将 object 插入该链表的头部。以上便是 SLAB 分配器使用物理内存的方法.

![](/assets/PDB/HK/HK000289.png)

在有的架构中内核的虚拟空间远远小于物理内存，那么只有一部分物理内存被线性映射，而绝大部分物理内存只有物理地址没有虚拟地址，线性映射区无法满足内核大块的连续虚拟内存需求，于是内核提供了 VMALLOC 内存分配器，其在内核空间划分了从 VMALLOC_START 到 VMALLOC_END 的虚拟区域，但内核有大块连续的虚拟内存需求时，VMALLOC 分配器就从该区域动态分配一段虚拟内存，然后从 Buddy 分配器中分配多个独立的物理页，并建立虚拟内存到这些物理页的页表，最后再把虚拟内存返回给调用者使用; 当调用者不再使用时，VMALLOC 回收这段虚拟内存为可用区域，并将其页表清除，释放物理页回 Buddy 分配器。由于物理页是独立的缘故，所以不能确保物理内存是连续的，因此 VMALLOC 分配器分配的内存特点是: 虚拟内存连续但物理内存不一定连续.

![](/assets/PDB/HK/TH001455.png)

Buddy 分配器能够提供的最大连续物理内存为 8MiB, 但有的需求场景需要大块连续的物理内存，于是内核提供了 CMA/DMA 分配器来实现大块连续内存的分配。CMA 分配器可以在内核初始化过程中，通过 CMDLINE 修改 E820 表将指定的物理内存区域进行预留，预留之后的物理内存系统不会对齐进行初始化，待内核初始化到一定程度，CMA 内存分配器在使用 bitmap 管理预留的内存，当调用者需要大块连续物理内存时，CMA 从 bitmap 中找到空闲的区域并将对应的 bit 置位，然后将连续的物理内存返回给调用者; 当调用者不再使用物理内存时，CMA 回收物理内存并将 bitmap 中对应的 bit 清零。CMA 由会独立维护大段物理内存，但当系统内存吃紧时，CMA 也会将部分物理内存迁移给 Buddy 分配器使用，反之当 CMA 需要更多连续物理内存时，内核也会尽量迁移腾挪出连续物理内存给 CMA 分配器使用. 写在最后，以上便是物理内存的生命周期，有的环节没有详细介绍，对细节感兴趣的同学可以参考如下链接:

> [BiscuitOS Blog](/blog/BiscuitOS_Catalogue/)

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="A3"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000Z.jpg)

#### 虚拟内存/虚拟地址

![](/assets/PDB/HK/TH001447.png)

计算机硬件架构中存在一种硬件 MMU(Memory Management Unit), 通常称为内存管理单元，有时也称为分页内存管理单元 PMMU(Paged memory management unit), 它是一种负责处理 CPU 的内存访问请求的计算机硬件。MMU 主要包含: 虚实地址翻译、访问权限控制。另外在计算机中存在实时模式和保护模式，当 CPU 处在实时模式下，CPU 看到的内存就是地址总线上的物理内存，那么 CPU 可以通过物理地址直接访问物理内存; 当计算机处在保护模式，MMU 的分页功能便随之启动，此时 CPU 看到的内存是一块连续的线性空间，那么称这块空间为**虚拟内存**, CPU 此时使用称为**虚拟地址**的地址来访问虚拟内存。虚拟内存的大小与计算机的位宽有关，例如 32 位系统虚拟内存的范围是 \[0, 4G), 而 64 位系统虚拟内存的范围是 \[0, 2^64). 虚拟内存的特点就是连续且范围巨大。

![](/assets/PDB/HK/TH001456.png)

系统将虚拟地址划分成两个区域，用户进程使用的虚拟内存区域称为**用户空间**(Userspace), 内核使用的虚拟区域称为**内核空间**(Kernel Space), 由于 MMU 的存在，用户进程访问内核空间或者内核访问用户空间都会引起系统错误。在不同架构中两个区域的划分有所不同:

![](/assets/PDB/HK/TH001457.png)

在 IA32 架构中，32 位地址总线的寻址能力为 \[0, 4G), 内核将虚拟内存从 PAGE_OFFSET 处分作两部分，\[0, PAGE_OFFSET) 为用户进程所使用的虚拟内存，而 \[PAGE_OFFSET, 4G) 为内核使用的虚拟内存。PAGE_OFFSET 可能是 2G 或者 3G，经典的分割是 \[0，3G) 是用户空间 \[3G, 4G) 为内核空间.

![](/assets/PDB/HK/TH001458.png)

在当前 AMD64/X64 架构中 64 位虚拟地址仅实现 48 位，剩下的高 16 位仅仅是作为符号拓展，组成最终的 64 位虚拟地址。高 16 位称为 Sign Extension 域，而低 48 位称为线性地址域，这样的 64 位虚拟地址称为 canonical-address 地址形式。Sign Extension 域要么全为 1 或者 0，对于 Sign Extension 不全为 0 或 1 的地址称为 Noncanonical-address.

![](/assets/PDB/HK/TH001459.png)

当前 AMD64/X64 架构中 Sign Extension 域为 16 位，那么虚拟内存会分作三部分，当 Sign Extension 全为 0 的区域称为 Canonical "Lower half", 也就是用户空间，128TiB 用户空间 \[0, 0x00007fff ffffffff) 占据了虚拟内存的底部. Sign Extension 全为 1 的区域称为 Canonical "High half", 也就是内核空间，128TiB 内核空间 \[0xffff8000 00000000, 0xffffffff ffffffff) 占据了虚拟内存顶部的位置。Sign Extension 域不全为 0 或 1 的范围 \[0x00008000 0000000, 0xffff8000 00000000) 称为 "Noncanonical Address Space", 落在这个区域的虚拟地址都是非法地址.

![](/assets/PDB/HK/TH001460.png)

随着技术的不断发展，AMD64/X64 64 位虚拟地址可以实现 56 根或者 64 根都能寻址，那么虚拟内存的 Canonical 区域的 "Lower Half" 和 "Higher Half" 将像 IA32 架构一样链接在一起，那么系统的内核空间和用户空间的范围将大大增加.

###### 页表

![](/assets/PDB/HK/TH001463.png)

当开启保护模式之后，系统使用的地址从物理地址变成了虚拟地址，但虚拟内存是抽象出来的概念，并不是实际的存储介质，那么当系统访问虚拟内存时，MMU 通过分页机制透明的将虚拟地址自动转换成物理地址，进而访问物理内存。**页表**是一块长度为 PAGE_SIZE 的物理内存, 其被划分为指定长度的 Entry，Entry 内记录了下一级页表的物理地址或者物理页的物理地址。MMU 将虚拟地址划分为多个区域，在不同的架构中每个区域的含义不同。MMU 在转换虚拟地址之前需要建立页表，页表可以通过缺页被动创建，也可以主动创建。在不同的架构中页表的组成有所不同，但其目的都是将虚拟地址通过分层查表的方式找到下一级页表，最终找到最终的物理地址。

![](/assets/PDB/HK/TH001464.png)

不同的架构地址总线数量不同，因此可寻址范围的不同导致页表的级数不同。在 IA32 架构中使用 32 位的地址总线寻址，因此使用两级页表的 32-Bit 分页机制。该机制中存在两种页表: **页目录页表**(Page Directory Table) 和**页表**(Page Table), 并且使用 CR3 寄存器指向 Page Directory 页表的物理地址. 虚拟地址 \[31, 22] 域称为页目录索引，用于在 Page Directory 页表中索引 PDE(Page Directory Entry), PDE 记录了下一级页表 Page Table 的物理地址。虚拟地址 \[21, 12] 域称为页表索引, 用于在 Page Table 页表中索引 PTE(Page Table Entry), PTE 记录了物理页的物理地址。虚拟地址 \[11, 0] 域称为页内偏移 PAGE_OFFSET，用于在物理页内找到对应的物理地址。

![](/assets/PDB/HK/TH001465.png)

在实现 48 位寻址的 AMD64/X64 架构中，使用 4-level 分页机制，该机制中存在四种页表: **PML4 页表**、**页目录指针页表**(Page-Directory Pointer Table)、**页目录页表**(Page-Directory Table) 和**页表**(Page Table), 并使用 CR3 寄存器指向 PML4 页表的物理地址。虚拟地址 \[47, 39] 域称为 PML4 索引，用于在 PML4 页表中获得 PML4E(PML4 Entry), PML4E 用于记录下一级 Page-Directory Pointer 页表的物理地址。虚拟地址 \[38, 30] 域称为页目录指针索引, 用于在 Page-Directory Pointer 页表中索引 PDPTE(Page-Directory Pointer Table Entry), PDPTE 记录了下一级页表 Page-Directory 的物理地址。虚拟地址 \[29, 21] 域称为页目录索引，用于在 Page-Directory 页表中索引 PDE(Page Directory Entry), PDE 记录了下一页表 Page Table 物理地址。虚拟地址 \[20, 12] 域称为页表索引，用于在 Page Table 页表中索引 PTE(Page Table Entry), PTE 记录了物理页的物理地址。虚拟地址 \[11, 0] 域称为页内偏移，用于在物理页内索引物理地址.

![](/assets/PDB/HK/TH001466.png)

在实现 56 位寻址的 AMD64/X64 架构中，使用 5-level 分页机制，该机制中存在四种页表: **PML5 页表**、**PML4 页表**、**页目录指针页表**(Page-Directory Pointer Table)、**页目录页表**(Page-Directory Table) 和**页表**(Page Table), 并使用 CR3 寄存器指向 PML5 页表的物理地址。虚拟地址 \[55, 48] 域称为 PML5 索引，用于在 PML5 页表中获得 PML5E(PML5 Entry), PML5E 记录了下一级页表 PML4 的物理地址。虚拟地址 \[47, 39] 域称为 PML4 索引，用于在 PML4 页表中获得 PML4E(PML4 Entry), PML4E 记录下一级 Page-Directory Pointer 页表的物理地址。虚拟地址 \[38, 30] 域称为页目录指针索引, 用于在 Page-Directory Pointer 页表中索引 PDPTE(Page-Directory Pointer Table Entry), PDPTE 记录了下一级页表 Page-Directory 的物理地址。虚拟地址 \[29, 21] 域称为页目录索引，用于在 Page-Directory 页表中索引 PDE(Page Directory Entry), PDE 记录了下一页表 Page Table 物理地址。虚拟地址 \[20, 12] 域称为页表索引，用于在 Page Table 页表中索引 PTE(Page Table Entry), PTE 记录了物理页的物理地址。虚拟地址 \[11, 0] 域称为页内偏移，用于在物理页内索引物理地址.

![](/assets/PDB/HK/HK000996.png)

MMU 通过遍历页表将一个虚拟地址转换成物理地址。例如在 X86 架构中使用 32-Bit 分页机制，系统使用 CR3 寄存器存储 Page Table 页表的起始物理地址，然后将虚拟地址 VA 向右偏移 22 位之后获得了虚拟地址的 Directory 区域, 结合 Page Directory 就可以获得对应的 PDE, 此时 PDE 内记录了 Page Table 页表的起始物理地址。

![](/assets/PDB/HK/TH001448.png)

在获得 PDE 之后，将虚拟地址 VA 向右偏移 12 位并屏蔽 Directory 区域之后获得了虚拟地址的 Table 区域，结合 Page Table 既可以获得对应的 PTE，此时 PTE 内记录了物理页的起始物理地址.

![](/assets/PDB/HK/HK000993.png)

在获得 PTE 之后，将虚拟地址 VA 的低 PAGE_SHIFT 位区域隔离出来就可以获得 Offset 区域，结合物理页的起始物理地址，就可以在物理页内找到一个物理地址，此地址就是虚拟地址映射的物理地址。

###### 用户空间

![](/assets/PDB/HK/TH001461.png)

用户空间(Userspace) 是用户进程运行时的地址空间，所谓**地址空间**可以理解为进程运行时的虚拟内存空间。当进程运行时会对其地址空间进行布局，其中进程从 \_\_executable_start 处开始将进程的代码段加载到 .text 区域，进程的数据段加载到 .data 区域，初始化为 0 的数据段加载到 .bss 段，以上是三个段是在程序运行前明确范围的区域。地址空间的**堆**(Heap) 区域是一块向高地址扩张的区域，为进程调用 malloc() 或 brk() 函数时提供小粒度虚拟内存。地址空间的**MMAP 映射区**是为进程提供大块虚拟内存的区域，进程可以通过 mmap() 或者 malloc() 函数从该区域分配虚拟内存，进程可以在该区域任意位置分配虚拟内存。地址空间的**栈**(Stack)区域是一块通常向地址扩张的区域，栈底是栈区域起始地址，栈顶则是栈最新扩张的区域，栈利用先进后出的模式存储进程运行时的数据。**argv/environ** 区域用于存储进程运行时的参数和环境变量信息。

![](/assets/PDB/HK/TH001462.png)

系统初始化正常运行时，系统存在多个用户进程同时运行的情况，由于进程隔离性的存在，每个进程都有各自的地址空间，并且每个进程只看得到自己的地址空间和内核空间，因此进程运行时会认为系统只有自己和内核线程在运行。由于该特性的存在，所有用户进程看到内核空间都是一致的，因此在进程切换的时候内核空间不需要切换，另外对于不同的进程就算用户空间虚拟地址相同，但两个虚拟内存对于的内容完全不是一个东西。

###### 内核空间

![](/assets/PDB/HK/HK000226.png)

内核空间(Kernel Space) 是内核运行时的地址空间，内核空间被换成多个区域，首先是线性映射区，所谓**线性映射区**就是内核将 PAGE_OFFSET 开始的连续虚拟内存与连续物理内存建立内核页表之后，区间内的虚拟地址可以通过线性关系就可以获得对应的物理地址。线性映射区是内核核心数据存储区域，其中包括了 \[KERNEL_START, KERNEL_END) 的内核镜像区，其中包含了内核的代码段、数据段和 BSS 段等，线性映射区对应的物理内存一般存在 ZONE_DMA、ZONE_DMA32 和 ZONE_NORMAL 中，另外这些物理内存由 Buddy 分配器进行维护，当内核需要线性映射区的内存时通过 Buddy 分配器进行分配，并通过线性关系直接获得对应的虚拟地址，当不再使用时，Buddy 分配器记性回收。线性映射区的虚拟内存还供给 SLAB/SLOB/SLUB 分配器使用。接下来是 VMALLOC 区域，所谓**VMALLOC 区域**指由 VMALLOC 分配器管理的 \[VMALLOC_START, VMALLOC_END) 的区域，内核可以从 VMALLOC 分配器动态分配连续的虚拟内存，分配的虚拟内存与 Buddy 分配器中分配的独立物理页建立页表，因此形成了虚拟内存连续但物理内存不连续的区域，当内核不再使用时，VMALLOC 分配器回收虚拟内存，并解除页表映射。接下来是 PKMAP 区域，所谓 **PKMAP 区域** 就是 PKMAP 内存分配器维护的一小块虚拟内存区域，其范围是 \[PKMAP_BASE, PKMAP_BASE + 2MiB), PKMAP 分配器提供了小块虚拟内存的临时映射，分配的虚拟内存与 Buddy 分配器分配的物理内存建立页表，当内核不再使用时，PKMAP 分配器回收虚拟内存以及摧毁页表释放物理页。最后一个是 FIXMAP 区域，所谓 **FIXMAP 区域**指由 FIXMAP 分配器管理的 \[FIXADDR_START, FIXADDR_END) 的区域，该区域的虚拟地址是固定分配指定的外设或功能的，内核在编译阶段就已经确认好的，内核在初始化阶段为该区域的虚拟内存分配了物理内存并建立页表。





















#### <span id="Z0">捐赠一下吧 🙂</span>

![MMU](/assets/PDB/BiscuitOS/kernel/HAB000036.jpg)
